"""
AI Memory System - í”„ë¡œì íŠ¸ë³„ ì¥ê¸° ê¸°ì–µ ì‹œìŠ¤í…œ
SQLite ê¸°ë°˜ ëŒ€í™” ì €ì¥, ê²€ìƒ‰, ìë™ ì •ë¦¬ ê¸°ëŠ¥ ì œê³µ
"""

import sqlite3
import json
import hashlib
import uuid
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple
from contextlib import contextmanager
import threading
import re
import os

class MemorySystem:
    def __init__(self, data_dir: str = None):
        self.data_dir = self._get_data_directory(data_dir)
        self._local = threading.local()
        self._storage_available = True

        # í”„ë¡œì íŠ¸ë³„ ë©”ëª¨ë¦¬ ë””ë ‰í† ë¦¬
        try:
            self.projects_dir = self.data_dir / "projects"
            self.projects_dir.mkdir(parents=True, exist_ok=True)

            # ê¸€ë¡œë²Œ ì„¤ì • ë””ë ‰í† ë¦¬
            self.global_dir = self.data_dir / "global"
            self.global_dir.mkdir(exist_ok=True)
        except (OSError, PermissionError) as e:
            print(f"âš ï¸ Warning: Cannot create memory directories: {e}")
            print(f"ğŸ’¡ Memory system will be disabled for this session.")
            self._storage_available = False

        # ì¤‘ìš”ë„ ë ˆë²¨ ì •ì˜
        self.IMPORTANCE_LEVELS = {
            1: {"name": "ì¦‰ì‹œì‚­ì œ", "ttl_days": 0, "description": "ì¸ì‚¬, í…ŒìŠ¤íŠ¸"},
            2: {"name": "ë‹¨ê¸°ë³´ê´€", "ttl_days": 3, "description": "ê°„ë‹¨í•œ ì§ˆë¬¸"},
            3: {"name": "1ì£¼ë³´ê´€", "ttl_days": 7, "description": "ì¼ë°˜ ëŒ€í™”"},
            4: {"name": "2ì£¼ë³´ê´€", "ttl_days": 14, "description": "ì •ë³´ì„± ì§ˆë¬¸"},
            5: {"name": "ê¸°ë³¸ë³´ê´€", "ttl_days": 30, "description": "ê¸°ë³¸ê°’"},
            6: {"name": "1ê°œì›”", "ttl_days": 30, "description": "ì½”ë“œ ê´€ë ¨"},
            7: {"name": "3ê°œì›”", "ttl_days": 90, "description": "í”„ë¡œì íŠ¸ ì„¤ì •"},
            8: {"name": "6ê°œì›”", "ttl_days": 180, "description": "ì¤‘ìš” ê²°ì •ì‚¬í•­"},
            9: {"name": "1ë…„ë³´ê´€", "ttl_days": 365, "description": "í•µì‹¬ ë¬¸ì„œí™”"},
            10: {"name": "ì˜êµ¬ë³´ê´€", "ttl_days": -1, "description": "ì‚¬ìš©ì ì¤‘ìš”í‘œì‹œ"}
        }

    def _get_data_directory(self, data_dir: str = None) -> Path:
        """
        ë©”ëª¨ë¦¬ ë°ì´í„° ì €ì¥ ë””ë ‰í† ë¦¬ ê²°ì •
        ìš°ì„ ìˆœìœ„: 1. ëª…ì‹œëœ ê²½ë¡œ 2. í™˜ê²½ë³€ìˆ˜ 3. ê¸°ë³¸ ê²½ë¡œ 4. í”„ë¡œì íŠ¸ ë¡œì»¬ í´ë°±
        """
        # 1. ëª…ì‹œì ìœ¼ë¡œ ì§€ì •ëœ ê²½ë¡œ
        if data_dir:
            path = Path(data_dir)
            if self._test_directory_access(path):
                return path

        # 2. í™˜ê²½ë³€ìˆ˜ AI_MEMORY_DIR
        env_dir = os.environ.get('AI_MEMORY_DIR')
        if env_dir:
            path = Path(env_dir)
            if self._test_directory_access(path):
                return path
            else:
                print(f"âš ï¸ Warning: AI_MEMORY_DIR '{env_dir}' is not accessible")

        # 3. ê¸°ë³¸ ê²½ë¡œ ì‹œë„
        default_path = Path("/mnt/e/ai-data/memory")
        if self._test_directory_access(default_path):
            return default_path

        # 4. í”„ë¡œì íŠ¸ ë¡œì»¬ í´ë°±
        current_repo = self._find_git_root()
        if current_repo:
            fallback_path = current_repo / ".ai-memory-data"
            print(f"ğŸ’¡ Using local memory storage: {fallback_path}")
            if self._test_directory_access(fallback_path):
                return fallback_path

        # 5. ìµœì¢… í´ë°± - í˜„ì¬ ë””ë ‰í† ë¦¬
        final_fallback = Path.cwd() / ".ai-memory-data"
        print(f"âš ï¸ Using current directory fallback: {final_fallback}")
        return final_fallback

    def _test_directory_access(self, path: Path) -> bool:
        """ë””ë ‰í† ë¦¬ ì ‘ê·¼ ê¶Œí•œ í…ŒìŠ¤íŠ¸"""
        try:
            path.mkdir(parents=True, exist_ok=True)
            # ì“°ê¸° ê¶Œí•œ í…ŒìŠ¤íŠ¸
            test_file = path / ".test_write"
            test_file.write_text("test")
            test_file.unlink()
            return True
        except (OSError, PermissionError):
            return False

    def _find_git_root(self) -> Optional[Path]:
        """í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ Git ë£¨íŠ¸ ì°¾ê¸°"""
        current = Path.cwd()
        while current != current.parent:
            if (current / ".git").exists():
                return current
            current = current.parent
        return None

    def get_project_id(self, project_path: str = None) -> str:
        """
        í”„ë¡œì íŠ¸ ID íšë“ ë˜ëŠ” ìƒì„±
        .ai-memory/project.jsonì—ì„œ UUID ë¡œë“œí•˜ê±°ë‚˜ ìƒˆë¡œ ìƒì„±
        """
        if project_path is None:
            project_path = os.getcwd()

        project_path = Path(project_path).resolve()
        memory_dir = project_path / ".ai-memory"
        project_file = memory_dir / "project.json"

        # ê¸°ì¡´ í”„ë¡œì íŠ¸ íŒŒì¼ í™•ì¸
        if project_file.exists():
            try:
                with open(project_file, 'r', encoding='utf-8') as f:
                    project_data = json.load(f)
                    return project_data['project_id']
            except (json.JSONDecodeError, KeyError):
                pass

        # ìƒˆ í”„ë¡œì íŠ¸ ID ìƒì„±
        project_id = str(uuid.uuid4())
        memory_dir.mkdir(exist_ok=True)

        project_data = {
            "project_id": project_id,
            "project_name": project_path.name,
            "project_path": str(project_path),
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat()
        }

        with open(project_file, 'w', encoding='utf-8') as f:
            json.dump(project_data, f, indent=2, ensure_ascii=False)

        return project_id

    def get_project_db_path(self, project_id: str) -> Path:
        """í”„ë¡œì íŠ¸ë³„ SQLite ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ ë°˜í™˜"""
        project_dir = self.projects_dir / project_id
        project_dir.mkdir(exist_ok=True)
        return project_dir / "memory.db"

    def _get_connection(self, project_id: str):
        """Thread-safe í”„ë¡œì íŠ¸ë³„ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
        if not hasattr(self._local, 'connections'):
            self._local.connections = {}

        if project_id not in self._local.connections:
            db_path = self.get_project_db_path(project_id)
            conn = sqlite3.connect(
                str(db_path),
                check_same_thread=False,
                timeout=30.0
            )
            conn.row_factory = sqlite3.Row

            # SQLite ì„±ëŠ¥ ìµœì í™”
            conn.execute("PRAGMA journal_mode=WAL")
            conn.execute("PRAGMA synchronous=NORMAL")
            conn.execute("PRAGMA cache_size=10000")
            conn.execute("PRAGMA foreign_keys=ON")

            self._local.connections[project_id] = conn

            # ìŠ¤í‚¤ë§ˆ ì´ˆê¸°í™”
            self._init_schema(conn)

        return self._local.connections[project_id]

    @contextmanager
    def transaction(self, project_id: str):
        """íŠ¸ëœì­ì…˜ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
        conn = self._get_connection(project_id)
        try:
            yield conn
            conn.commit()
        except Exception:
            conn.rollback()
            raise

    def _init_schema(self, conn):
        """ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì´ˆê¸°í™”"""

        # ëŒ€í™” ê¸°ë¡ í…Œì´ë¸”
        conn.execute("""
            CREATE TABLE IF NOT EXISTS conversations (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                user_query TEXT NOT NULL,
                ai_response TEXT NOT NULL,
                model_used VARCHAR(50),
                importance_score INTEGER DEFAULT 5,
                tags TEXT,  -- JSON ë°°ì—´
                session_id VARCHAR(50),
                token_count INTEGER,
                response_time_ms INTEGER,
                project_context TEXT,  -- í”„ë¡œì íŠ¸ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ ì •ë³´
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                expires_at DATETIME  -- TTL ê¸°ë°˜ ìë™ ì‚­ì œìš©
            )
        """)

        # ëŒ€í™” ìš”ì•½ í…Œì´ë¸”
        conn.execute("""
            CREATE TABLE IF NOT EXISTS conversation_summaries (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                date_range TEXT,  -- "2024-09-01 to 2024-09-07"
                summary TEXT,     -- AI ìƒì„± ìš”ì•½
                conversation_count INTEGER,
                importance_level INTEGER,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # ì¤‘ìš” ì‚¬ì‹¤ í…Œì´ë¸”
        conn.execute("""
            CREATE TABLE IF NOT EXISTS important_facts (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                fact TEXT NOT NULL,
                category VARCHAR(100),  -- code, config, decision, etc.
                source_conversation_id INTEGER,
                user_marked BOOLEAN DEFAULT FALSE,
                ai_suggested BOOLEAN DEFAULT FALSE,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (source_conversation_id) REFERENCES conversations(id)
            )
        """)

        # ì‚¬ìš©ì ì„ í˜¸ë„ í…Œì´ë¸”
        conn.execute("""
            CREATE TABLE IF NOT EXISTS user_preferences (
                key VARCHAR(100) PRIMARY KEY,
                value TEXT,
                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # ë²¡í„° ì„ë² ë”© í…Œì´ë¸” (Qdrant ë™ê¸°í™”ìš©)
        conn.execute("""
            CREATE TABLE IF NOT EXISTS conversation_embeddings (
                conversation_id INTEGER PRIMARY KEY,
                embedding_vector BLOB,  -- ì„ë² ë”© ë²¡í„° (ë¡œì»¬ í´ë°±ìš©)
                qdrant_point_id TEXT,   -- Qdrant í¬ì¸íŠ¸ ID
                sync_status INTEGER DEFAULT 0,  -- 0: ëŒ€ê¸°, 1: ë™ê¸°í™” ì™„ë£Œ, -1: ì‹¤íŒ¨
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (conversation_id) REFERENCES conversations(id)
            )
        """)

        # FTS5 ì „ë¬¸ ê²€ìƒ‰ í…Œì´ë¸”
        conn.execute("""
            CREATE VIRTUAL TABLE IF NOT EXISTS conversations_fts USING fts5(
                user_query,
                ai_response,
                content='conversations',
                content_rowid='id'
            )
        """)

        # ì¸ë±ìŠ¤ ìƒì„±
        indexes = [
            "CREATE INDEX IF NOT EXISTS idx_conversations_timestamp ON conversations(timestamp)",
            "CREATE INDEX IF NOT EXISTS idx_conversations_importance ON conversations(importance_score)",
            "CREATE INDEX IF NOT EXISTS idx_conversations_expires_at ON conversations(expires_at)",
            "CREATE INDEX IF NOT EXISTS idx_conversations_session_id ON conversations(session_id)",
            "CREATE INDEX IF NOT EXISTS idx_conversations_model_used ON conversations(model_used)",
            "CREATE INDEX IF NOT EXISTS idx_important_facts_category ON important_facts(category)",
            "CREATE INDEX IF NOT EXISTS idx_conversation_embeddings_sync_status ON conversation_embeddings(sync_status)"
        ]

        for index_sql in indexes:
            conn.execute(index_sql)

        # FTS5 íŠ¸ë¦¬ê±° (ìë™ ë™ê¸°í™”)
        conn.execute("""
            CREATE TRIGGER IF NOT EXISTS conversations_ai_insert AFTER INSERT ON conversations
            BEGIN
                INSERT INTO conversations_fts(rowid, user_query, ai_response)
                VALUES (NEW.id, NEW.user_query, NEW.ai_response);
            END
        """)

        conn.execute("""
            CREATE TRIGGER IF NOT EXISTS conversations_ai_update AFTER UPDATE ON conversations
            BEGIN
                UPDATE conversations_fts SET
                    user_query = NEW.user_query,
                    ai_response = NEW.ai_response
                WHERE rowid = NEW.id;
            END
        """)

        conn.execute("""
            CREATE TRIGGER IF NOT EXISTS conversations_ai_delete AFTER DELETE ON conversations
            BEGIN
                DELETE FROM conversations_fts WHERE rowid = OLD.id;
            END
        """)

    def calculate_importance_score(self, user_query: str, ai_response: str,
                                 model_used: str = None, context: Dict = None) -> int:
        """
        ëŒ€í™”ì˜ ì¤‘ìš”ë„ ì ìˆ˜ ìë™ ê³„ì‚° (1-10)
        """
        score = 5  # ê¸°ë³¸ê°’
        context = context or {}

        query_lower = user_query.lower()
        response_lower = ai_response.lower()
        combined_text = f"{query_lower} {response_lower}"

        # ë†’ì€ ì¤‘ìš”ë„ í‚¤ì›Œë“œ
        high_importance_keywords = [
            # ê¸°ìˆ  ì„¤ì •
            "ì„¤ì •", "config", "configuration", "í™˜ê²½ë³€ìˆ˜", "environment",
            "architecture", "design pattern", "ì•„í‚¤í…ì²˜", "ì„¤ê³„",

            # ë¬¸ì œ í•´ê²°
            "ë²„ê·¸", "ì—ëŸ¬", "ì˜¤ë¥˜", "ë¬¸ì œ", "í•´ê²°", "fix", "bug", "error",
            "issue", "problem", "solution", "trouble",

            # ì¤‘ìš” ê°œë°œ
            "êµ¬í˜„", "implementation", "ì•Œê³ ë¦¬ì¦˜", "algorithm", "ìµœì í™”",
            "optimization", "performance", "ì„±ëŠ¥", "ë³´ì•ˆ", "security",

            # ê²°ì •ì‚¬í•­
            "ê²°ì •", "decision", "ì •ì±…", "policy", "ë°©í–¥", "direction",
            "ì „ëµ", "strategy", "ê³„íš", "plan"
        ]

        # ë‚®ì€ ì¤‘ìš”ë„ í‚¤ì›Œë“œ
        low_importance_keywords = [
            "ì•ˆë…•", "hello", "hi", "í…ŒìŠ¤íŠ¸", "test", "í™•ì¸", "check",
            "ê°ì‚¬", "thank", "ì¢‹ì•„", "ì¢‹ë‹¤", "ê´œì°®", "ok", "okay"
        ]

        # í‚¤ì›Œë“œ ê¸°ë°˜ ì ìˆ˜ ì¡°ì •
        high_count = sum(1 for keyword in high_importance_keywords if keyword in combined_text)
        low_count = sum(1 for keyword in low_importance_keywords if keyword in combined_text)

        score += min(high_count, 3)  # ìµœëŒ€ +3
        score -= min(low_count, 2)   # ìµœëŒ€ -2

        # ì‘ë‹µ ê¸¸ì´ ê³ ë ¤ (ê¸´ ì‘ë‹µ = ë” ìƒì„¸í•œ ì •ë³´)
        response_length = len(ai_response)
        if response_length > 2000:
            score += 2
        elif response_length > 1000:
            score += 1
        elif response_length < 100:
            score -= 1

        # ì½”ë“œ í¬í•¨ ì—¬ë¶€
        code_patterns = [
            r'```[\s\S]*?```',  # ì½”ë“œ ë¸”ë¡
            r'`[^`]+`',         # ì¸ë¼ì¸ ì½”ë“œ
            r'def\s+\w+',       # Python í•¨ìˆ˜
            r'function\s+\w+',  # JavaScript í•¨ìˆ˜
            r'class\s+\w+',     # í´ë˜ìŠ¤ ì •ì˜
            r'import\s+\w+',    # Import ë¬¸
            r'SELECT\s+.*FROM', # SQL ì¿¼ë¦¬
        ]

        for pattern in code_patterns:
            if re.search(pattern, ai_response, re.IGNORECASE):
                score += 1
                break

        # ëª¨ë¸ íƒ€ì… ê³ ë ¤
        if model_used == "code-7b":
            score += 1  # ì½”ë”© ëª¨ë¸ ì‚¬ìš©ì‹œ +1

        # ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜
        if context.get("user_saved", False):
            score = 10  # ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ì €ì¥í•œ ê²½ìš°
        elif context.get("user_important", False):
            score = max(score, 8)

        # ì§ˆë¬¸ ê¸¸ì´ ê³ ë ¤ (ìƒì„¸í•œ ì§ˆë¬¸ì¼ìˆ˜ë¡ ì¤‘ìš”)
        if len(user_query) > 200:
            score += 1

        return max(1, min(10, score))

    def save_conversation(self, project_id: str, user_query: str, ai_response: str,
                         model_used: str = None, session_id: str = None,
                         token_count: int = None, response_time_ms: int = None,
                         context: Dict = None, tags: List[str] = None) -> Optional[int]:
        """
        ëŒ€í™”ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        ê¶Œí•œ ì˜¤ë¥˜ ì‹œ None ë°˜í™˜
        """
        if not self._storage_available:
            return None

        try:
            context = context or {}
            importance_score = self.calculate_importance_score(
                user_query, ai_response, model_used, context
            )

            # TTL ê³„ì‚°
            ttl_days = self.IMPORTANCE_LEVELS[importance_score]["ttl_days"]
            expires_at = None
            if ttl_days > 0:
                expires_at = datetime.now() + timedelta(days=ttl_days)

            with self.transaction(project_id) as conn:
                cursor = conn.execute("""
                    INSERT INTO conversations (
                        user_query, ai_response, model_used, importance_score,
                        tags, session_id, token_count, response_time_ms,
                        project_context, expires_at
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    user_query, ai_response, model_used, importance_score,
                    json.dumps(tags or [], ensure_ascii=False), session_id,
                    token_count, response_time_ms, json.dumps(context, ensure_ascii=False),
                    expires_at
                ))

                conversation_id = cursor.lastrowid

                # ì„ë² ë”© íì— ì¶”ê°€ (ë‚˜ì¤‘ì— ë¹„ë™ê¸° ì²˜ë¦¬)
                conn.execute("""
                    INSERT INTO conversation_embeddings (conversation_id, sync_status)
                    VALUES (?, 0)
                """, (conversation_id,))

                return conversation_id

        except (OSError, PermissionError) as e:
            print(f"âš ï¸ Cannot save conversation to memory: {e}")
            return None
        except Exception as e:
            print(f"âš ï¸ Memory save error: {e}")
            return None

    def search_conversations(self, project_id: str, query: str = None,
                           importance_min: int = None, limit: int = 10,
                           offset: int = 0) -> List[Dict[str, Any]]:
        """
        ëŒ€í™” ê²€ìƒ‰ (í‚¤ì›Œë“œ + ì¤‘ìš”ë„ í•„í„°)
        """
        if not self._storage_available:
            return []

        try:
            with self.transaction(project_id) as conn:
                if query:
                    # FTS5 ì „ë¬¸ ê²€ìƒ‰
                    cursor = conn.execute("""
                        SELECT c.* FROM conversations c
                        JOIN conversations_fts fts ON c.id = fts.rowid
                        WHERE conversations_fts MATCH ?
                        AND (? IS NULL OR c.importance_score >= ?)
                        ORDER BY c.timestamp DESC
                        LIMIT ? OFFSET ?
                    """, (query, importance_min, importance_min, limit, offset))
                else:
                    # ì¼ë°˜ ê²€ìƒ‰
                    cursor = conn.execute("""
                        SELECT * FROM conversations
                        WHERE (? IS NULL OR importance_score >= ?)
                        ORDER BY timestamp DESC
                        LIMIT ? OFFSET ?
                    """, (importance_min, importance_min, limit, offset))

                results = []
                for row in cursor.fetchall():
                    result = dict(row)
                    result['tags'] = json.loads(result['tags'] or '[]')
                    result['project_context'] = json.loads(result['project_context'] or '{}')
                    results.append(result)

                return results

        except (OSError, PermissionError) as e:
            print(f"âš ï¸ Cannot search conversations: {e}")
            return []
        except Exception as e:
            print(f"âš ï¸ Search error: {e}")
            return []

    def get_conversation_stats(self, project_id: str) -> Dict[str, Any]:
        """í”„ë¡œì íŠ¸ ë©”ëª¨ë¦¬ í†µê³„"""
        if not self._storage_available:
            return {
                'total_conversations': 0,
                'avg_importance': 0,
                'oldest_conversation': None,
                'latest_conversation': None,
                'importance_distribution': {},
                'model_usage': {}
            }

        try:
            with self.transaction(project_id) as conn:
                # ê¸°ë³¸ í†µê³„
                cursor = conn.execute("""
                    SELECT
                        COUNT(*) as total_conversations,
                        AVG(importance_score) as avg_importance,
                        MIN(timestamp) as oldest_conversation,
                        MAX(timestamp) as latest_conversation
                    FROM conversations
                """)
                stats = dict(cursor.fetchone())

                # ì¤‘ìš”ë„ë³„ ë¶„í¬
                cursor = conn.execute("""
                    SELECT importance_score, COUNT(*) as count
                    FROM conversations
                    GROUP BY importance_score
                    ORDER BY importance_score
                """)
                stats['importance_distribution'] = {
                    row['importance_score']: row['count']
                    for row in cursor.fetchall()
                }

                # ëª¨ë¸ë³„ ì‚¬ìš©ëŸ‰
                cursor = conn.execute("""
                    SELECT model_used, COUNT(*) as count
                    FROM conversations
                    WHERE model_used IS NOT NULL
                    GROUP BY model_used
                """)
                stats['model_usage'] = {
                    row['model_used']: row['count']
                    for row in cursor.fetchall()
                }

                return stats

        except (OSError, PermissionError) as e:
            print(f"âš ï¸ Cannot get conversation stats: {e}")
            return {
                'total_conversations': 0,
                'avg_importance': 0,
                'oldest_conversation': None,
                'latest_conversation': None,
                'importance_distribution': {},
                'model_usage': {}
            }
        except Exception as e:
            print(f"âš ï¸ Stats error: {e}")
            return {
                'total_conversations': 0,
                'avg_importance': 0,
                'oldest_conversation': None,
                'latest_conversation': None,
                'importance_distribution': {},
                'model_usage': {}
            }

# ê¸€ë¡œë²Œ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤
_current_instance = None

def get_memory_system() -> MemorySystem:
    """í˜„ì¬ í™œì„±í™”ëœ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _current_instance
    if _current_instance is None:
        _current_instance = MemorySystem()
    return _current_instance

def set_memory_system(instance: MemorySystem):
    """ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ë³€ê²½"""
    global _current_instance
    _current_instance = instance

# ê¸°ë³¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (í•˜ìœ„ í˜¸í™˜ì„±)
memory_system = get_memory_system()