#!/usr/bin/env python3
"""
Memory Database Schema Migration Script

ì´ì „ ìŠ¤í‚¤ë§ˆì˜ ë©”ëª¨ë¦¬ DBë¥¼ ìµœì‹  êµ¬ì¡°ë¡œ ì—…ê·¸ë ˆì´ë“œí•©ë‹ˆë‹¤.
ì£¼ìš” ë³€ê²½ ì‚¬í•­:
- conversation_embeddings í…Œì´ë¸”ì— id ì»¬ëŸ¼ ì¶”ê°€
- sync_status, synced_at ì»¬ëŸ¼ ì¶”ê°€
- qdrant_point_id ì»¬ëŸ¼ ì¶”ê°€

ì‚¬ìš©ë²•:
    python scripts/migrate_memory_schema.py [--dry-run] [--project PROJECT_ID]

    --dry-run: ì‹¤ì œ ë³€ê²½ ì—†ì´ ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íšë§Œ ì¶œë ¥
    --project: íŠ¹ì • í”„ë¡œì íŠ¸ë§Œ ë§ˆì´ê·¸ë ˆì´ì…˜ (ì—†ìœ¼ë©´ ì „ì²´)
"""

import os
import sys
import sqlite3
import argparse
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Tuple

# ë©”ëª¨ë¦¬ ë””ë ‰í† ë¦¬ ê²½ë¡œ
AI_MEMORY_DIR = os.getenv('AI_MEMORY_DIR', '/mnt/e/ai-data/memory')
PROJECTS_DIR = Path(AI_MEMORY_DIR) / 'projects'


def check_schema_version(db_path: Path) -> Tuple[bool, str]:
    """
    ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ë²„ì „ í™•ì¸

    Returns:
        (needs_migration, reason)
    """
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # conversation_embeddings í…Œì´ë¸” êµ¬ì¡° í™•ì¸
        cursor.execute("PRAGMA table_info(conversation_embeddings)")
        columns = {row[1]: row[2] for row in cursor.fetchall()}

        conn.close()

        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_columns = {
            'id': 'INTEGER',
            'conversation_id': 'INTEGER',
            'embedding_vector': 'BLOB',
            'sync_status': 'TEXT',
            'synced_at': 'TEXT',
            'qdrant_point_id': 'TEXT',
            'created_at': 'DATETIME'
        }

        missing_columns = []
        for col_name, col_type in required_columns.items():
            if col_name not in columns:
                missing_columns.append(col_name)

        if missing_columns:
            return True, f"ëˆ„ë½ëœ ì»¬ëŸ¼: {', '.join(missing_columns)}"

        return False, "ìŠ¤í‚¤ë§ˆê°€ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤"

    except Exception as e:
        return False, f"ìŠ¤í‚¤ë§ˆ í™•ì¸ ì˜¤ë¥˜: {str(e)}"


def migrate_database(db_path: Path, dry_run: bool = False) -> bool:
    """
    ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰

    Args:
        db_path: ë§ˆì´ê·¸ë ˆì´ì…˜í•  DB íŒŒì¼ ê²½ë¡œ
        dry_run: Trueë©´ ì‹¤ì œ ë³€ê²½í•˜ì§€ ì•ŠìŒ

    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    try:
        # ë°±ì—… ìƒì„±
        if not dry_run:
            backup_path = db_path.parent / f"{db_path.stem}_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db"
            import shutil
            shutil.copy2(db_path, backup_path)
            print(f"  âœ… ë°±ì—… ìƒì„±ë¨: {backup_path.name}")

        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # í˜„ì¬ ìŠ¤í‚¤ë§ˆ í™•ì¸
        cursor.execute("PRAGMA table_info(conversation_embeddings)")
        existing_columns = {row[1] for row in cursor.fetchall()}

        migrations = []

        # 1. id ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¶”ê°€ (PRIMARY KEYë¡œ ì¬ìƒì„± í•„ìš”)
        if 'id' not in existing_columns:
            migrations.append("id PRIMARY KEYë¡œ í…Œì´ë¸” ì¬ìƒì„±")

            if not dry_run:
                # ê¸°ì¡´ ë°ì´í„° ë°±ì—…
                cursor.execute("""
                    CREATE TABLE conversation_embeddings_old AS
                    SELECT * FROM conversation_embeddings
                """)

                # ìƒˆ í…Œì´ë¸” ìƒì„±
                cursor.execute("DROP TABLE conversation_embeddings")
                cursor.execute("""
                    CREATE TABLE conversation_embeddings (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        conversation_id INTEGER NOT NULL,
                        embedding_vector BLOB NOT NULL,
                        sync_status TEXT DEFAULT 'pending',
                        synced_at TEXT,
                        qdrant_point_id TEXT,
                        created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                        FOREIGN KEY (conversation_id) REFERENCES conversations (id)
                    )
                """)

                # ë°ì´í„° ë³µì› (embedding_vectorê°€ NULLì¸ í–‰ì€ ì œì™¸)
                cursor.execute("""
                    INSERT INTO conversation_embeddings
                    (conversation_id, embedding_vector, created_at)
                    SELECT conversation_id, embedding_vector,
                           COALESCE(created_at, CURRENT_TIMESTAMP)
                    FROM conversation_embeddings_old
                    WHERE embedding_vector IS NOT NULL
                """)

                cursor.execute("DROP TABLE conversation_embeddings_old")

        else:
            # id ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ê°œë³„ ì»¬ëŸ¼ ì¶”ê°€
            if 'sync_status' not in existing_columns:
                migrations.append("sync_status ì»¬ëŸ¼ ì¶”ê°€")
                if not dry_run:
                    cursor.execute("""
                        ALTER TABLE conversation_embeddings
                        ADD COLUMN sync_status TEXT DEFAULT 'pending'
                    """)

            if 'synced_at' not in existing_columns:
                migrations.append("synced_at ì»¬ëŸ¼ ì¶”ê°€")
                if not dry_run:
                    cursor.execute("""
                        ALTER TABLE conversation_embeddings
                        ADD COLUMN synced_at TEXT
                    """)

            if 'qdrant_point_id' not in existing_columns:
                migrations.append("qdrant_point_id ì»¬ëŸ¼ ì¶”ê°€")
                if not dry_run:
                    cursor.execute("""
                        ALTER TABLE conversation_embeddings
                        ADD COLUMN qdrant_point_id TEXT
                    """)

        # ì¸ë±ìŠ¤ ìƒì„±
        if not dry_run:
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_embeddings_conversation
                ON conversation_embeddings(conversation_id)
            """)
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_embeddings_sync_status
                ON conversation_embeddings(sync_status)
            """)

        if not dry_run:
            conn.commit()
            print(f"  âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì ìš©ë¨: {', '.join(migrations)}")
        else:
            print(f"  ğŸ“‹ ì ìš©ë  ë³€ê²½ì‚¬í•­: {', '.join(migrations)}")

        conn.close()
        return True

    except Exception as e:
        print(f"  âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {str(e)}")
        if not dry_run:
            conn.rollback()
        return False


def find_memory_databases() -> List[Path]:
    """ë©”ëª¨ë¦¬ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ëª©ë¡ ë°˜í™˜"""
    if not PROJECTS_DIR.exists():
        print(f"âŒ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {PROJECTS_DIR}")
        return []

    databases = []
    for project_dir in PROJECTS_DIR.iterdir():
        if project_dir.is_dir():
            db_path = project_dir / 'memory.db'
            if db_path.exists():
                databases.append(db_path)

    return sorted(databases)


def main():
    parser = argparse.ArgumentParser(
        description='ë©”ëª¨ë¦¬ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆë¥¼ ìµœì‹  ë²„ì „ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='ì‹¤ì œ ë³€ê²½ ì—†ì´ ë§ˆì´ê·¸ë ˆì´ì…˜ ëŒ€ìƒë§Œ í‘œì‹œ'
    )
    parser.add_argument(
        '--project',
        type=str,
        help='íŠ¹ì • í”„ë¡œì íŠ¸ IDë§Œ ë§ˆì´ê·¸ë ˆì´ì…˜'
    )

    args = parser.parse_args()

    print("=" * 60)
    print("ë©”ëª¨ë¦¬ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜")
    print("=" * 60)
    print()

    if args.dry_run:
        print("ğŸ” DRY RUN ëª¨ë“œ - ì‹¤ì œ ë³€ê²½ ì—†ì´ í™•ì¸ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤\n")

    # ë°ì´í„°ë² ì´ìŠ¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    databases = find_memory_databases()

    if args.project:
        databases = [db for db in databases if args.project in str(db)]
        if not databases:
            print(f"âŒ í”„ë¡œì íŠ¸ì˜ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.project}")
            return 1

    if not databases:
        print("âŒ ë©”ëª¨ë¦¬ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return 1

    print(f"{len(databases)}ê°œì˜ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤\n")

    # ë§ˆì´ê·¸ë ˆì´ì…˜ í•„ìš” ì—¬ë¶€ í™•ì¸
    to_migrate = []
    up_to_date = []

    for db_path in databases:
        project_id = db_path.parent.name
        needs_migration, reason = check_schema_version(db_path)

        if needs_migration:
            to_migrate.append((db_path, project_id, reason))
        else:
            up_to_date.append((db_path, project_id))

    # ê²°ê³¼ ì¶œë ¥
    if up_to_date:
        print(f"âœ… ìµœì‹  ìƒíƒœ ({len(up_to_date)}ê°œ):")
        for db_path, project_id in up_to_date:
            print(f"   â€¢ {project_id}")
        print()

    if to_migrate:
        print(f"ğŸ”„ ë§ˆì´ê·¸ë ˆì´ì…˜ í•„ìš” ({len(to_migrate)}ê°œ):")
        for db_path, project_id, reason in to_migrate:
            print(f"   â€¢ {project_id}: {reason}")
        print()

        # ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
        if not args.dry_run:
            confirm = input("ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? [y/N]: ")
            if confirm.lower() != 'y':
                print("âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤")
                return 0
            print()

        success_count = 0
        for db_path, project_id, reason in to_migrate:
            print(f"{project_id} ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘...")
            if migrate_database(db_path, args.dry_run):
                success_count += 1
            print()

        print("=" * 60)
        if args.dry_run:
            print(f"ğŸ“‹ {len(to_migrate)}ê°œì˜ ë°ì´í„°ë² ì´ìŠ¤ê°€ ë§ˆì´ê·¸ë ˆì´ì…˜ë  ì˜ˆì •ì…ë‹ˆë‹¤")
        else:
            print(f"âœ… {success_count}/{len(to_migrate)}ê°œì˜ ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")

        if success_count < len(to_migrate):
            print(f"âš ï¸  ì‹¤íŒ¨: {len(to_migrate) - success_count}ê°œ")
            return 1
    else:
        print("âœ… ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ê°€ ìµœì‹  ìƒíƒœì…ë‹ˆë‹¤!")

    return 0


if __name__ == '__main__':
    sys.exit(main())