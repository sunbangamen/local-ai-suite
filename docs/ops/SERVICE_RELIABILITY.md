# Service Reliability Operations Guide

**ì‘ì„±ì¼**: 2025-10-09
**ëŒ€ìƒ**: Phase 2 ìš´ì˜ì
**ëª©ì **: Issue #14 Service Reliability ê°œì„  ì‚¬í•­ ìš´ì˜ ê°€ì´ë“œ

---

## ğŸ“‹ ê°œìš”

ì´ ë¬¸ì„œëŠ” Phase 2 ì´ì¤‘í™” êµ¬ì¡°ì˜ ìš´ì˜ ì ˆì°¨, ì¥ì•  ëŒ€ì‘, ëª¨ë‹ˆí„°ë§ ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

### ì£¼ìš” ê°œì„  ì‚¬í•­

- âœ… **LLM ì„œë²„ ì´ì¤‘í™”**: inference-chat (3B) + inference-code (7B)
- âœ… **ìë™ í˜ì¼ì˜¤ë²„**: LiteLLM priority ê¸°ë°˜ ì¬ì‹œë„
- âœ… **í—¬ìŠ¤ì²´í¬ ê°•í™”**: ëª¨ë“  ì„œë¹„ìŠ¤ì— `/health` ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
- âœ… **ì˜ì¡´ì„± ê´€ë¦¬**: `depends_on: service_healthy` ì¡°ê±´ ì ìš©
- âœ… **ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜**: Qdrant í˜¸ì¶œì— exponential backoff ì¬ì‹œë„

---

## ğŸš€ ì„œë¹„ìŠ¤ ì‹œì‘ ë° ì¤‘ì§€

### Phase 2 ì‹œì‘

```bash
# ì „ì²´ ì„œë¹„ìŠ¤ ì‹œì‘
docker compose -f docker/compose.p2.yml up -d

# ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
docker compose -f docker/compose.p2.yml ps

# ë¡œê·¸ í™•ì¸
docker compose -f docker/compose.p2.yml logs -f
```

### ê°œë³„ ì„œë¹„ìŠ¤ ì¬ì‹œì‘

```bash
# Chat ëª¨ë¸ ì„œë²„ë§Œ ì¬ì‹œì‘
docker compose -f docker/compose.p2.yml restart inference-chat

# Code ëª¨ë¸ ì„œë²„ë§Œ ì¬ì‹œì‘
docker compose -f docker/compose.p2.yml restart inference-code

# API Gateway ì¬ì‹œì‘
docker compose -f docker/compose.p2.yml restart api-gateway

# RAG ì„œë¹„ìŠ¤ ì¬ì‹œì‘
docker compose -f docker/compose.p2.yml restart rag
```

### ì„œë¹„ìŠ¤ ì¤‘ì§€

```bash
# ì „ì²´ ì¤‘ì§€
docker compose -f docker/compose.p2.yml down

# íŠ¹ì • ì„œë¹„ìŠ¤ë§Œ ì¤‘ì§€
docker compose -f docker/compose.p2.yml stop inference-chat
```

---

## ğŸ” ëª¨ë‹ˆí„°ë§ ë° í—¬ìŠ¤ì²´í¬

### í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸

| ì„œë¹„ìŠ¤ | URL | ì •ìƒ ì‘ë‹µ |
|--------|-----|----------|
| **inference-chat** | http://localhost:8001/health | 200 OK |
| **inference-code** | http://localhost:8004/health | 200 OK |
| **api-gateway** | http://localhost:8000/health | 200 OK |
| **rag** | http://localhost:8002/health | 200 OK (ì˜ì¡´ì„± healthy) |
| **embedding** | http://localhost:8003/health | 200 OK |
| **qdrant** | http://localhost:6333/collections | 200 OK |

### í—¬ìŠ¤ì²´í¬ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# health_check.sh

echo "=== Phase 2 Health Check ==="

services=(
  "inference-chat:8001"
  "inference-code:8004"
  "api-gateway:8000"
  "rag:8002"
  "embedding:8003"
)

for service in "${services[@]}"; do
  name="${service%%:*}"
  port="${service##*:}"

  if curl -fsS "http://localhost:$port/health" > /dev/null 2>&1; then
    echo "âœ… $name: healthy"
  else
    echo "âŒ $name: unhealthy"
  fi
done

# Qdrant íŠ¹ë³„ ì²´í¬
if curl -fsS "http://localhost:6333/collections" > /dev/null 2>&1; then
  echo "âœ… qdrant: healthy"
else
  echo "âŒ qdrant: unhealthy"
fi
```

### Docker í—¬ìŠ¤ ìƒíƒœ í™•ì¸

```bash
# ì „ì²´ ì„œë¹„ìŠ¤ ìƒíƒœ
docker compose -f docker/compose.p2.yml ps

# í—¬ìŠ¤ì²´í¬ ì„¸ë¶€ ì •ë³´
docker inspect <container_id> | jq '.[0].State.Health'

# Unhealthy ì»¨í…Œì´ë„ˆ ì°¾ê¸°
docker ps --filter "health=unhealthy"
```

### GPU ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§

```bash
# ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
watch -n 1 nvidia-smi

# VRAM ì‚¬ìš©ëŸ‰ë§Œ í™•ì¸
nvidia-smi --query-gpu=memory.used,memory.total --format=csv -l 1

# ì»¨í…Œì´ë„ˆë³„ GPU ì‚¬ìš©ëŸ‰ (í”„ë¡œì„¸ìŠ¤ IDë¡œ ì¶”ì )
nvidia-smi pmon -s um
```

---

## ğŸš¨ ì¥ì•  ëŒ€ì‘ ê°€ì´ë“œ

### Scenario 1: inference-chat ì¥ì• 

**ì¦ìƒ**:
- `docker ps`ì—ì„œ inference-chatì´ unhealthy ë˜ëŠ” exited ìƒíƒœ
- Chat ìš”ì²­ì´ ìë™ìœ¼ë¡œ inference-codeë¡œ failoverë¨

**í™•ì¸**:
```bash
# ì»¨í…Œì´ë„ˆ ìƒíƒœ
docker ps -a | grep inference-chat

# ë¡œê·¸ í™•ì¸
docker logs inference-chat --tail 100

# GPU ë©”ëª¨ë¦¬ í™•ì¸
nvidia-smi
```

**ëŒ€ì‘**:
1. **ìë™ ì¬ì‹œì‘ ëŒ€ê¸°** (Dockerê°€ ìë™ ì¬ì‹œì‘ ì‹œë„)
2. **ìˆ˜ë™ ì¬ì‹œì‘**:
   ```bash
   docker compose -f docker/compose.p2.yml restart inference-chat
   ```
3. **GPU OOM ì‹œ** GPU ë ˆì´ì–´ ì¡°ì •:
   ```bash
   # .env íŒŒì¼ ìˆ˜ì •
   CHAT_N_GPU_LAYERS=999  # â†’ 500ìœ¼ë¡œ ê°ì†Œ

   docker compose -f docker/compose.p2.yml up -d inference-chat
   ```

**ë³µêµ¬ í™•ì¸**:
```bash
# í—¬ìŠ¤ì²´í¬
curl http://localhost:8001/health

# ëª¨ë¸ ë¡œë”© í™•ì¸
curl http://localhost:8001/v1/models

# ê°„ë‹¨í•œ ì¶”ë¡  í…ŒìŠ¤íŠ¸
curl -X POST http://localhost:8001/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"messages": [{"role": "user", "content": "ì•ˆë…•"}]}'
```

---

### Scenario 2: Qdrant ì—°ê²° ì‹¤íŒ¨

**ì¦ìƒ**:
- RAG `/health` ì—”ë“œí¬ì¸íŠ¸ê°€ 503 ë°˜í™˜
- RAG ë¡œê·¸ì— Qdrant ì—°ê²° ì—ëŸ¬

**í™•ì¸**:
```bash
# Qdrant ìƒíƒœ
docker ps | grep qdrant

# Qdrant ë¡œê·¸
docker logs qdrant --tail 100

# Qdrant API í…ŒìŠ¤íŠ¸
curl http://localhost:6333/collections
```

**ëŒ€ì‘**:
1. **Qdrant ì¬ì‹œì‘**:
   ```bash
   docker compose -f docker/compose.p2.yml restart qdrant
   ```

2. **ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜ í™•ì¸**:
   - RAG ì„œë¹„ìŠ¤ëŠ” ìë™ìœ¼ë¡œ 3íšŒ ì¬ì‹œë„ (exponential backoff)
   - ë¡œê·¸ì—ì„œ `tenacity` ì¬ì‹œë„ ë©”ì‹œì§€ í™•ì¸

3. **ë°ì´í„° ì†ìƒ ì‹œ ë³µêµ¬**:
   ```bash
   # Qdrant ë°ì´í„° ì‚­ì œ í›„ ì¬ì‹œì‘
   docker compose -f docker/compose.p2.yml down qdrant
   rm -rf /mnt/e/ai-data/vectors/qdrant/*
   docker compose -f docker/compose.p2.yml up -d qdrant

   # ë¬¸ì„œ ì¬ì¸ë±ì‹±
   curl -X POST http://localhost:8002/index?collection=default
   ```

---

### Scenario 3: API Gateway í˜ì¼ì˜¤ë²„ ë™ì‘ í™•ì¸

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
```bash
# 1. inference-chat ê°•ì œ ì¤‘ì§€
docker stop inference-chat

# 2. Chat ìš”ì²­ ì „ì†¡
curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "chat-7b",
    "messages": [{"role": "user", "content": "Hello"}]
  }'

# 3. API Gateway ë¡œê·¸ í™•ì¸ (failover ë°œìƒ ì—¬ë¶€)
docker logs api-gateway --tail 50 | grep -i retry

# 4. inference-chat ì¬ì‹œì‘
docker start inference-chat
```

**ì˜ˆìƒ ë™ì‘**:
- API Gatewayê°€ inference-chat ì—°ê²° ì‹¤íŒ¨ ê°ì§€
- priority=2ì¸ inference-codeë¡œ ìë™ ì „í™˜
- 3íšŒ ì¬ì‹œë„ í›„ ì‘ë‹µ ë°˜í™˜ (ì•½ 10-30ì´ˆ ì†Œìš”)

---

### Scenario 4: ì „ì²´ ì„œë¹„ìŠ¤ ì¬ì‹œì‘ (ìˆœì„œ ë³´ì¥)

**ì•ˆì „í•œ ì¬ì‹œì‘ ì ˆì°¨**:
```bash
# 1. ì „ì²´ ì¤‘ì§€
docker compose -f docker/compose.p2.yml down

# 2. ì˜ì¡´ì„± ìˆœì„œëŒ€ë¡œ ì‹œì‘ (Docker Composeê°€ ìë™ ì²˜ë¦¬)
docker compose -f docker/compose.p2.yml up -d

# 3. ê° ì„œë¹„ìŠ¤ healthy ëŒ€ê¸°
echo "Waiting for services to be healthy..."
sleep 60

# 4. ì „ì²´ í—¬ìŠ¤ì²´í¬
./health_check.sh
```

**ì‹œì‘ ìˆœì„œ** (Docker Composeê°€ ìë™ ê´€ë¦¬):
1. qdrant, embedding, inference-chat, inference-code (ë³‘ë ¬)
2. api-gateway (inference ì„œë²„ healthy ëŒ€ê¸°)
3. rag (qdrant, embedding, api-gateway healthy ëŒ€ê¸°)

---

## âš™ï¸ ì„¤ì • ë³€ê²½

### GPU ë ˆì´ì–´ ì¡°ì • (ë©”ëª¨ë¦¬ ìµœì í™”)

**í˜„ì¬ ì„¤ì •** (`.env` ë˜ëŠ” `.env.example`):
```bash
CHAT_N_GPU_LAYERS=999    # 3B ëª¨ë¸ ì „ì²´ GPU
CODE_N_GPU_LAYERS=20     # 7B ëª¨ë¸ ì¼ë¶€ GPU
```

**OOM ë°œìƒ ì‹œ ì¡°ì •**:
```bash
# Chat ëª¨ë¸ GPU ë ˆì´ì–´ ê°ì†Œ
CHAT_N_GPU_LAYERS=500

# Code ëª¨ë¸ GPU ë ˆì´ì–´ ê°ì†Œ
CODE_N_GPU_LAYERS=15

# ì¬ì‹œì‘
docker compose -f docker/compose.p2.yml up -d inference-chat inference-code
```

### íƒ€ì„ì•„ì›ƒ ì¡°ì •

**í˜„ì¬ ì„¤ì •** (`.env.example`):
```bash
LLM_REQUEST_TIMEOUT=60           # ì¼ë°˜ LLM í˜¸ì¶œ
RAG_LLM_TIMEOUT=120              # RAG LLM í˜¸ì¶œ
QDRANT_TIMEOUT=30                # Qdrant í˜¸ì¶œ
EMBEDDING_TIMEOUT=30             # Embedding í˜¸ì¶œ
```

**ëŠë¦° ì‘ë‹µ ì‹œ ì¦ê°€**:
```bash
# .env íŒŒì¼ ìˆ˜ì •
LLM_REQUEST_TIMEOUT=120
RAG_LLM_TIMEOUT=180

# RAG ì„œë¹„ìŠ¤ë§Œ ì¬ì‹œì‘
docker compose -f docker/compose.p2.yml restart rag
```

### Qdrant ì¬ì‹œë„ ì„¤ì •

**í˜„ì¬ ì„¤ì •**:
```bash
QDRANT_MAX_RETRIES=3             # ì¬ì‹œë„ íšŸìˆ˜
QDRANT_RETRY_MIN_WAIT=2          # ìµœì†Œ ëŒ€ê¸° (ì´ˆ)
QDRANT_RETRY_MAX_WAIT=10         # ìµœëŒ€ ëŒ€ê¸° (ì´ˆ)
```

**ë¶ˆì•ˆì •í•œ ë„¤íŠ¸ì›Œí¬ ì‹œ ì¡°ì •**:
```bash
# .env íŒŒì¼ ìˆ˜ì •
QDRANT_MAX_RETRIES=5
QDRANT_RETRY_MIN_WAIT=3
QDRANT_RETRY_MAX_WAIT=20

# RAG ì„œë¹„ìŠ¤ ì¬ì‹œì‘
docker compose -f docker/compose.p2.yml restart rag
```

---

## ğŸ“Š ë¡œê·¸ ë¶„ì„

### ì¤‘ìš” ë¡œê·¸ íŒ¨í„´

**ì •ìƒ ë™ì‘**:
```
# Inference ì„œë²„
llama server listening at http://0.0.0.0:8001

# API Gateway
litellm.router: Checking health of all models

# RAG
INFO:     Application startup complete

# Qdrant
INFO: Qdrant is ready to serve
```

**ì¥ì•  ì§•í›„**:
```
# GPU OOM
CUDA error: out of memory

# Qdrant ì—°ê²° ì‹¤íŒ¨
qdrant_client.exceptions.ConnectionError

# íƒ€ì„ì•„ì›ƒ
httpx.ReadTimeout

# LiteLLM ì¬ì‹œë„
litellm.router: Retrying request to http://inference-chat:8001
```

### ë¡œê·¸ ìˆ˜ì§‘ ëª…ë ¹ì–´

```bash
# ì „ì²´ ì„œë¹„ìŠ¤ ë¡œê·¸ (ìµœê·¼ 100ì¤„)
docker compose -f docker/compose.p2.yml logs --tail 100

# íŠ¹ì • ì„œë¹„ìŠ¤ ì‹¤ì‹œê°„ ì¶”ì 
docker compose -f docker/compose.p2.yml logs -f inference-chat

# ì—ëŸ¬ ë¡œê·¸ë§Œ í•„í„°ë§
docker compose -f docker/compose.p2.yml logs | grep -i error

# íŠ¹ì • ì‹œê°„ëŒ€ ë¡œê·¸
docker compose -f docker/compose.p2.yml logs --since "2025-10-09T10:00:00"
```

---

## ğŸ”§ ì„±ëŠ¥ íŠœë‹

### ì¶”ë¡  ì†ë„ ê°œì„ 

**ë³‘ë ¬ ì²˜ë¦¬ ì¦ê°€**:
```bash
# .env íŒŒì¼ ìˆ˜ì •
LLAMA_PARALLEL=2  # ê¸°ë³¸ê°’ 1 â†’ 2ë¡œ ì¦ê°€

# ì¬ì‹œì‘
docker compose -f docker/compose.p2.yml restart inference-chat inference-code
```

**ë°°ì¹˜ í¬ê¸° ì¡°ì •**:
```bash
# compose.p2.yml ìˆ˜ì •
-b 256  # ê¸°ë³¸ê°’ 128 â†’ 256ìœ¼ë¡œ ì¦ê°€

# ì¬ë¹Œë“œ ë° ì¬ì‹œì‘
docker compose -f docker/compose.p2.yml up -d --build
```

### RAG ê²€ìƒ‰ ì„±ëŠ¥

**TopK ì¡°ì •**:
```bash
# .env íŒŒì¼
RAG_TOPK=2  # ê¸°ë³¸ê°’ 4 â†’ 2ë¡œ ê°ì†Œ (ì†ë„ í–¥ìƒ)

# RAG ì¬ì‹œì‘
docker compose -f docker/compose.p2.yml restart rag
```

**ì²­í¬ í¬ê¸° ì¡°ì •**:
```bash
# ì‘ì€ ë¬¸ì„œ: ë¹ ë¥¸ ê²€ìƒ‰
RAG_CHUNK_SIZE=256
RAG_CHUNK_OVERLAP=50

# í° ë¬¸ì„œ: ì •í™•ë„ ìš°ì„ 
RAG_CHUNK_SIZE=1024
RAG_CHUNK_OVERLAP=200
```

---

## ğŸ“ˆ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (Prometheus)

### Prometheus ì„¤ì • ì˜ˆì‹œ

```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'rag-service'
    static_configs:
      - targets: ['localhost:8002']

  - job_name: 'api-gateway'
    static_configs:
      - targets: ['localhost:8000']
```

### ì£¼ìš” ë©”íŠ¸ë¦­

- **http_request_duration_seconds**: ì‘ë‹µ ì‹œê°„
- **http_requests_total**: ìš”ì²­ ìˆ˜
- **http_request_size_bytes**: ìš”ì²­ í¬ê¸°
- **http_response_size_bytes**: ì‘ë‹µ í¬ê¸°

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì¼ì¼ ìš´ì˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ëª¨ë“  ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ (`docker ps`)
- [ ] í—¬ìŠ¤ì²´í¬ ì‹¤í–‰ (`./health_check.sh`)
- [ ] GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸ (`nvidia-smi`)
- [ ] ì—ëŸ¬ ë¡œê·¸ í™•ì¸ (`docker logs | grep -i error`)
- [ ] ë””ìŠ¤í¬ ê³µê°„ í™•ì¸ (`df -h /mnt/e/ai-data`)

### ì£¼ê°„ ìœ ì§€ë³´ìˆ˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Qdrant ë°±ì—… ìˆ˜í–‰
- [ ] ë¡œê·¸ ë¡œí…Œì´ì…˜ (`docker logs --since 7d`)
- [ ] ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¦¬ë·°
- [ ] ì˜ì¡´ì„± ë²„ì „ í™•ì¸ ë° ì—…ë°ì´íŠ¸

---

## ğŸ†˜ ê¸´ê¸‰ ì—°ë½ì²˜ ë° ë¦¬ì†ŒìŠ¤

**ë¬¸ì„œ**:
- ì•„í‚¤í…ì²˜ ë¹„êµ: `docs/architecture/PHASE2_VS_PHASE3_COMPARISON.md`
- GPU ë©”ëª¨ë¦¬ ê²€ì¦: `docs/architecture/GPU_MEMORY_VERIFICATION.md`
- í—¬ìŠ¤ì²´í¬ ìŠ¤í™: `docs/architecture/HEALTHCHECK_SPECIFICATION.md`

**ì´ìŠˆ íŠ¸ë˜í‚¹**:
- GitHub Issue #14: Service Reliability ê°œì„ 
- ì§„í–‰ ìƒí™©: `docs/progress/v1/ri_7.md`

**ì°¸ê³  ìë£Œ**:
- LiteLLM Failover: https://docs.litellm.ai/docs/routing
- Tenacity Retry: https://tenacity.readthedocs.io/
- Docker Healthcheck: https://docs.docker.com/compose/compose-file/compose-file-v3/#healthcheck

---

**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-10-09
**ë‹´ë‹¹ì**: ì‹œìŠ¤í…œ ìš´ì˜íŒ€
**ê²€í†  ì£¼ê¸°**: ì›” 1íšŒ
