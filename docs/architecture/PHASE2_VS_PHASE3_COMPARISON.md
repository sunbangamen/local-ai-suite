# Phase 2 vs Phase 3 Architecture Comparison

**ì‘ì„±ì¼**: 2025-10-09
**ëª©ì **: Issue #14 Service Reliability ê°œì„ ì„ ìœ„í•œ Phase 2/3 êµ¬ì¡° ì°¨ì´ ë¶„ì„

---

## ğŸ“Š í•µì‹¬ ì°¨ì´ì  ìš”ì•½

| êµ¬ì„± ìš”ì†Œ | Phase 2 (í˜„ì¬) | Phase 3 (ì´ì¤‘í™”) | ë³€ê²½ í•„ìš” ì—¬ë¶€ |
|----------|----------------|------------------|---------------|
| **Inference ì„œë²„** | ë‹¨ì¼ (`inference:8001`) | ì´ì¤‘í™” (`inference-chat:8001`, `inference-code:8004`) | âœ… í•„ìˆ˜ |
| **LiteLLM Config** | `config.p2.yaml` (ë‹¨ì¼ ì„œë²„) | `config.p1.yaml` (ì´ì¤‘í™” ì„œë²„) | âœ… í•„ìˆ˜ |
| **Healthcheck** | inferenceë§Œ ìˆìŒ | embedding, qdrant ì¶”ê°€ | âœ… í•„ìˆ˜ |
| **depends_on** | ê¸°ë³¸ ì˜ì¡´ì„±ë§Œ | `condition: service_healthy` ì‚¬ìš© | âœ… í•„ìˆ˜ |
| **ë©”ëª¨ë¦¬ ì œí•œ** | 8G | 6G (ê°ê°) | âœ… í•„ìˆ˜ |
| **ì¶”ê°€ ì„œë¹„ìŠ¤** | - | MCP, Memory API/Maintainer | âŒ Phase 2ì— ë¶ˆí•„ìš” |

---

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨

### í˜„ì¬ Phase 2 êµ¬ì¡° (SPOF ì¡´ì¬)
```mermaid
graph TD
    User[User] --> Gateway[API Gateway :8000]
    Gateway --> Inference[Inference :8001 - SPOF]
    Gateway --> RAG[RAG :8002]
    RAG --> Embedding[Embedding :8003 - No Healthcheck]
    RAG --> Qdrant[Qdrant :6333 - No Healthcheck]

    style Inference fill:#f99,stroke:#f00,stroke-width:3px
    style Embedding fill:#ffa,stroke:#fa0,stroke-width:2px
    style Qdrant fill:#ffa,stroke:#fa0,stroke-width:2px
```

### ê°œì„  í›„ Phase 2 êµ¬ì¡° (ì´ì¤‘í™” + ì¬ì‹œë„)
```mermaid
graph TD
    User[User] --> Gateway[API Gateway :8000]
    Gateway --> InferenceChat[Inference-Chat 3B :8001]
    Gateway -.failover.-> InferenceCode[Inference-Code 7B :8004]
    Gateway --> RAG[RAG :8002]
    RAG -- retry/backoff --> Embedding[Embedding :8003]
    RAG -- retry/backoff --> Qdrant[Qdrant :6333]

    InferenceChat -.healthcheck.-> Gateway
    InferenceCode -.healthcheck.-> Gateway
    Embedding -.healthcheck.-> RAG
    Qdrant -.healthcheck.-> RAG

    Gateway -.depends_on: service_healthy.-> InferenceChat
    Gateway -.depends_on: service_healthy.-> InferenceCode
    RAG -.depends_on: service_healthy.-> Qdrant
    RAG -.depends_on: service_healthy.-> Embedding

    style InferenceChat fill:#9f9,stroke:#0a0,stroke-width:2px
    style InferenceCode fill:#9f9,stroke:#0a0,stroke-width:2px
    style Embedding fill:#9f9,stroke:#0a0,stroke-width:2px
    style Qdrant fill:#9f9,stroke:#0a0,stroke-width:2px
```

---

## ğŸ”§ ìƒì„¸ ë³€ê²½ ì‚¬í•­

### 1. Inference ì„œë²„ ì´ì¤‘í™”

**Phase 2 (í˜„ì¬)**:
```yaml
services:
  inference:
    image: ghcr.io/ggerganov/llama.cpp:server
    ports: ["8001:8001"]
    command: >
      --model /models/${CHAT_MODEL:-Qwen2.5-7B-Instruct-Q4_K_M.gguf}
    deploy:
      resources:
        limits:
          memory: 8G
```

**Phase 3 (ì´ì¤‘í™”)**:
```yaml
services:
  inference-chat:
    image: ghcr.io/ggerganov/llama.cpp:server
    ports: ["8001:8001"]
    command: >
      --model /models/${CHAT_MODEL:-Qwen2.5-3B-Instruct-Q4_K_M.gguf}
    deploy:
      resources:
        limits:
          memory: 6G

  inference-code:
    image: ghcr.io/ggerganov/llama.cpp:server
    ports: ["8004:8001"]
    command: >
      --model /models/${CODE_MODEL:-qwen2.5-coder-7b-instruct-q4_k_m.gguf}
    deploy:
      resources:
        limits:
          memory: 6G
```

**ë³€ê²½ ì´ìœ **:
- **SPOF ì œê±°**: ë‹¨ì¼ ì„œë²„ ì¥ì•  ì‹œ ì „ì²´ ì‹œìŠ¤í…œ ë‹¤ìš´ ë°©ì§€
- **ë©”ëª¨ë¦¬ ìµœì í™”**: 3B + 7Bë¡œ ì´ VRAM 6GB ì´ë‚´ ìœ ì§€
- **ì¥ì•  ê²©ë¦¬**: Chat ëª¨ë¸ ì¥ì•  ì‹œ Code ëª¨ë¸ë¡œ Failover ê°€ëŠ¥

---

### 2. LiteLLM í˜ì¼ì˜¤ë²„ êµ¬ì„±

**Phase 2 (í˜„ì¬)**:
```yaml
model_list:
  - model_name: chat-7b
    litellm_params:
      api_base: http://inference:8001/v1  # ë‹¨ì¼ ì„œë²„
  - model_name: code-7b
    litellm_params:
      api_base: http://inference:8001/v1  # ë™ì¼ ì„œë²„
```

**Phase 3 (ì´ì¤‘í™” + í˜ì¼ì˜¤ë²„)**:
```yaml
model_list:
  # Chat ëª¨ë¸ Primary
  - model_name: chat-7b
    litellm_params:
      api_base: http://inference-chat:8001/v1
      priority: 1

  # Chat ëª¨ë¸ Fallback (code ì„œë²„ë¡œ)
  - model_name: chat-7b
    litellm_params:
      api_base: http://inference-code:8001/v1
      priority: 2

  # Code ëª¨ë¸
  - model_name: code-7b
    litellm_params:
      api_base: http://inference-code:8001/v1

router:
  num_retries: 3
  retry_on_status_codes: [500, 502, 503, 504, 408]
  retry_strategy: sequence
  timeout: 60
```

**í˜ì¼ì˜¤ë²„ ë™ì‘**:
1. `inference-chat` ì¥ì•  ì‹œ â†’ `inference-code`ë¡œ ìë™ ì „í™˜ (30ì´ˆ ì´ë‚´)
2. ì¬ì‹œë„ 3íšŒ (exponential backoff)
3. 5xx ì—ëŸ¬ ë° íƒ€ì„ì•„ì›ƒ ìë™ ì¬ì‹œë„

---

### 3. Healthcheck ì¶”ê°€

| ì„œë¹„ìŠ¤ | Phase 2 | Phase 3 | ë³€ê²½ ì‚¬í•­ |
|--------|---------|---------|-----------|
| **inference** | âœ… ìˆìŒ | N/A (ë¶„ë¦¬ë¨) | - |
| **inference-chat** | N/A | âœ… ì¶”ê°€ í•„ìš” | `curl http://localhost:8001/health` |
| **inference-code** | N/A | âœ… ì¶”ê°€ í•„ìš” | `curl http://localhost:8001/health` |
| **embedding** | âŒ ì—†ìŒ | âœ… ìˆìŒ | Python urllib ê¸°ë°˜ ì²´í¬ ì¶”ê°€ |
| **qdrant** | âŒ ì—†ìŒ | âœ… ìˆìŒ | `/proc/net/tcp` í¬íŠ¸ ë¦¬ìŠ¤ë‹ ì²´í¬ |
| **api-gateway** | âœ… ìˆìŒ | âœ… ìˆìŒ | ë³€ê²½ ì—†ìŒ |
| **rag** | âŒ ì—†ìŒ | âŒ ì—†ìŒ | ì¶”ê°€ í•„ìš” (Qdrant/Embedding ì˜ì¡´ì„± ì²´í¬) |

**Qdrant Healthcheck íŠ¹ì´ì‚¬í•­**:
```yaml
healthcheck:
  # QdrantëŠ” HTTP í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìœ¼ë¯€ë¡œ /proc/net/tcp í™œìš©
  # 6333 í¬íŠ¸(hex:18BD) LISTEN ìƒíƒœ í™•ì¸
  test: ["CMD-SHELL", "grep -q ':18BD' /proc/net/tcp || exit 1"]
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 30s
```

---

### 4. depends_on ì˜ì¡´ì„± ì¡°ê±´ ê°•í™”

**Phase 2 (í˜„ì¬)**:
```yaml
api-gateway:
  depends_on:
    - inference  # ë‹¨ìˆœ ì‹œì‘ ìˆœì„œë§Œ ë³´ì¥

rag:
  depends_on:
    - qdrant
    - embedding
    - api-gateway  # í—¬ìŠ¤ ìƒíƒœ ë¬´ê´€
```

**Phase 3 (service_healthy ì¡°ê±´)**:
```yaml
api-gateway:
  depends_on:
    inference-chat:
      condition: service_healthy
    inference-code:
      condition: service_healthy

rag:
  depends_on:
    qdrant:
      condition: service_healthy
    embedding:
      condition: service_healthy
    api-gateway:
      condition: service_healthy

memory-maintainer:
  depends_on:
    qdrant:
      condition: service_healthy
    embedding:
      condition: service_healthy
```

**íš¨ê³¼**:
- ì„œë¹„ìŠ¤ê°€ **ì‹¤ì œ ì¤€ë¹„ ì™„ë£Œ** í›„ì—ë§Œ ì˜ì¡´ ì„œë¹„ìŠ¤ ì‹œì‘
- ìˆœí™˜ ì˜ì¡´ì„± ë°©ì§€ (`start_period` ì„¤ì •ìœ¼ë¡œ ì´ˆê¸° íƒ€ì„ì•„ì›ƒ íšŒí”¼)
- ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘ ì‹œ ìë™ ìˆœì„œ ë³´ì¥

---

## ğŸ§ª GPU ë©”ëª¨ë¦¬ ê²€ì¦

### ì‹œë‚˜ë¦¬ì˜¤ 1: 7B + 7B (ê¸°ì¡´ ê³„íš)
| ëª¨ë¸ | VRAM ì‚¬ìš©ëŸ‰ | ì´í•© |
|------|-------------|------|
| Chat 7B | ~4.4GB | |
| Code 7B | ~4.4GB | |
| **ì´í•©** | | **8.8GB** âŒ (ì´ˆê³¼) |

**ê²°ë¡ **: RTX 4050 6GBë¡œëŠ” ë¶ˆê°€ëŠ¥

---

### ì‹œë‚˜ë¦¬ì˜¤ 2: 3B + 7B (ëŒ€ì•ˆ - ì±„íƒ)
| ëª¨ë¸ | VRAM ì‚¬ìš©ëŸ‰ | ì´í•© |
|------|-------------|------|
| Chat 3B | ~2.2GB | |
| Code 7B | ~4.4GB | |
| **ì´í•©** | | **6.6GB** âš ï¸ (ê²½ê³„) |

**ê²°ë¡ **:
- ì‹¤ì œ ì‹¤í–‰ ì‹œ ì•½ 80% ì ìœ  (5.3GB)
- `--n-gpu-layers` ì¡°ì •ìœ¼ë¡œ ì¼ë¶€ CPU ì˜¤í”„ë¡œë“œ í•„ìš”
- **ì±„íƒ**: Phase 2 ê¸°ë³¸ `CHAT_MODEL=Qwen2.5-3B-Instruct-Q4_K_M.gguf`

---

### ì‹œë‚˜ë¦¬ì˜¤ 3: 3B + 7B (CPU Fallback)
| êµ¬ì„± | GPU | CPU |
|------|-----|-----|
| Chat 3B | `--n-gpu-layers 999` (ì „ë¶€) | - |
| Code 7B | `--n-gpu-layers 20` (ì¼ë¶€) | ë‚˜ë¨¸ì§€ ë ˆì´ì–´ |

**íš¨ê³¼**:
- VRAM ì‚¬ìš©ëŸ‰: ~4.5GB (ì—¬ìœ  í™•ë³´)
- Code ëª¨ë¸ ì†ë„ ì•½ê°„ ì €í•˜ (í—ˆìš© ê°€ëŠ¥)
- ì•ˆì •ì„± ìµœìš°ì„ 

---

## âš™ï¸ í™˜ê²½ë³€ìˆ˜ í‘œì¤€í™”

### ì¶”ê°€ í•„ìš” í™˜ê²½ë³€ìˆ˜

```bash
# .env.example ì¶”ê°€ í•­ëª©

# ========== Timeout Configuration ==========
LLM_REQUEST_TIMEOUT=60           # LLM API í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
LLM_CONNECT_TIMEOUT=10           # LLM ì—°ê²° íƒ€ì„ì•„ì›ƒ (ì´ˆ)
RAG_LLM_TIMEOUT=120              # RAG ì‹œìŠ¤í…œ LLM íƒ€ì„ì•„ì›ƒ (ì´ˆ)
QDRANT_TIMEOUT=30                # Qdrant í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
EMBEDDING_TIMEOUT=30             # Embedding í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ (ì´ˆ)

# ========== Model Configuration ==========
# Phase 2: 3B Chat + 7B Code (GPU ë©”ëª¨ë¦¬ ìµœì í™”)
CHAT_MODEL=Qwen2.5-3B-Instruct-Q4_K_M.gguf
CODE_MODEL=qwen2.5-coder-7b-instruct-q4_k_m.gguf

# Phase 3: 7B Chat + 7B Code (ê¶Œì¥ 8GB+ VRAM)
# CHAT_MODEL=Qwen2.5-7B-Instruct-Q4_K_M.gguf
# CODE_MODEL=qwen2.5-coder-7b-instruct-q4_k_m.gguf

# ========== Retry Configuration ==========
QDRANT_MAX_RETRIES=3             # Qdrant ì¬ì‹œë„ íšŸìˆ˜
QDRANT_RETRY_MIN_WAIT=2          # ìµœì†Œ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
QDRANT_RETRY_MAX_WAIT=10         # ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)

# ========== Service URLs (internal) ==========
INFERENCE_CHAT_URL=http://inference-chat:8001
INFERENCE_CODE_URL=http://inference-code:8001
```

---

## ğŸ”„ ë³€ê²½ ì ìš© ìˆœì„œ

### ë‹¨ê³„ë³„ ì˜ì¡´ì„±

```mermaid
graph TD
    A[1. compose.p2.yml ìˆ˜ì •] --> B[2. config.p2.yaml ìˆ˜ì •]
    B --> C[3. .env.example ì—…ë°ì´íŠ¸]
    C --> D[4. Healthcheck ì¶”ê°€]
    D --> E[5. RAG ì¬ì‹œë„ ë¡œì§]
    E --> F[6. í†µí•© í…ŒìŠ¤íŠ¸]

    style A fill:#e1f5ff
    style B fill:#e1f5ff
    style C fill:#e1f5ff
    style D fill:#fff4e1
    style E fill:#fff4e1
    style F fill:#e1ffe1
```

---

## ğŸ“ Phase 3ì™€ì˜ ì°¨ì´ì  (Phase 2ì—ì„œ ì œì™¸í•  ê²ƒ)

Phase 3ì—ëŠ” ìˆì§€ë§Œ **Phase 2ì—ëŠ” ë¶ˆí•„ìš”**í•œ ì„œë¹„ìŠ¤:

1. **mcp-server**: MCP í†µí•©ì€ Phase 3 ì „ìš©
2. **memory-maintainer**: ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ Phase 3 ì „ìš©
3. **memory-api**: ë©”ëª¨ë¦¬ REST API Phase 3 ì „ìš©

**Phase 2 ìµœì¢… ì„œë¹„ìŠ¤ ëª©ë¡**:
- `inference-chat` (3B ëª¨ë¸)
- `inference-code` (7B ëª¨ë¸)
- `api-gateway`
- `rag`
- `embedding`
- `qdrant`

---

## ğŸ¯ ì„±ê³µ ê¸°ì¤€ (DoD)

### Phase 2 ê°œì„  ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] `compose.p2.yml`ì— ì´ì¤‘í™” êµ¬ì¡° ì ìš© (inference-chat + inference-code)
- [ ] `config.p2.yaml`ì— í˜ì¼ì˜¤ë²„ ë¼ìš°í„° êµ¬ì„±
- [ ] `.env.example`ì— íƒ€ì„ì•„ì›ƒ í™˜ê²½ë³€ìˆ˜ ì¶”ê°€
- [ ] Embedding/Qdrant healthcheck ì¶”ê°€
- [ ] RAG `/health` ì—”ë“œí¬ì¸íŠ¸ ê°•í™”
- [ ] `depends_on: service_healthy` ì¡°ê±´ ì ìš©
- [ ] RAG Qdrant í˜¸ì¶œ ì¬ì‹œë„ ë¡œì§ (tenacity)
- [ ] Failover í…ŒìŠ¤íŠ¸ í†µê³¼ (30ì´ˆ ì´ë‚´ ë³µêµ¬)
- [ ] Qdrant ì¬ì—°ê²° í…ŒìŠ¤íŠ¸ í†µê³¼ (5ë¶„ ì´ë‚´)
- [ ] ë¬¸ì„œí™” ì™„ë£Œ (`SERVICE_RELIABILITY.md`)

---

## ğŸ“š ì°¸ê³  ìë£Œ

- **LiteLLM Failover**: https://docs.litellm.ai/docs/routing
- **Docker Healthcheck**: https://docs.docker.com/compose/compose-file/compose-file-v3/#healthcheck
- **Tenacity Retry**: https://tenacity.readthedocs.io/

---

**ì‘ì„±ì**: Claude Code
**ë¦¬ë·° í•„ìš”**: compose.p2.yml ìˆ˜ì • ì „ GPU ë©”ëª¨ë¦¬ ì‹¤ì¸¡ ê¶Œì¥
