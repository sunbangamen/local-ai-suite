# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

Local AI Suite is a comprehensive local AI system designed to run entirely offline on external SSDs with GPU acceleration. It provides a phase-by-phase deployment approach for running local LLM models with OpenAI-compatible APIs, RAG (Retrieval-Augmented Generation), and MCP (Model Context Protocol) server capabilities.

**Key Goals:**
- Complete offline AI system for portability across different PCs
- RTX 4050 + WSL2 optimized GPU acceleration
- OpenAI API compatibility for VS Code/Cursor integration
- Korean language support with coding-specific model selection

## Architecture Overview

### Phase-Based Deployment

The system implements a progressive deployment strategy:

**Phase 1 (Basic AI Serving):**
- llama.cpp inference server (port 8001) - Direct model serving
- LiteLLM API gateway (port 8000) - OpenAI compatibility layer
- Automatic model selection between chat and code models

**Phase 2 (RAG System with Service Reliability):**
- **Dual LLM Servers**: inference-chat (3B, port 8001) + inference-code (7B, port 8004)
- **Auto Failover**: LiteLLM priority-based fallback mechanism
- **Health Checks**: All services with `/health` endpoints and dependency validation
- **Retry Logic**: Qdrant operations with exponential backoff
- FastEmbed embedding service (port 8003) - PyTorch-free embedding generation
- Qdrant vector database (port 6333) - High-performance vector storage
- PostgreSQL database (port 5432) - Metadata and search logs
- RAG service (port 8002) - Document indexing and query processing
- Korean document support with contextual answers

**Phase 3 (MCP Integration):**
- MCP server (port 8020) - FastMCP framework with 14 tools
- Playwright web automation (4 tools) - Screenshots, scraping, UI analysis
- Notion API integration (3 tools) - Page creation, search, web-to-notion
- File system and Git integration for Claude Desktop

**Phase 4 (Desktop Application):**
- Electron-based Claude Desktop-style app
- Smart model selection (auto/manual modes)
- Markdown code block rendering with copy functionality
- Web/Electron environment compatibility

### Core Components

**Model Management:**
- GGUF format models in `models/` directory
- Automatic model selection based on query content analysis
- Supports both general chat and coding-specific models

**Service Architecture:**
- Docker Compose orchestration with health checks
- GPU passthrough for NVIDIA RTX 4050
- Service dependencies and startup ordering
- Environment-based configuration

**AI CLI Interface:**
- Intelligent model selection based on keywords and patterns
- Interactive and batch modes
- Token length control and timeout handling

## Common Development Commands

### Service Management
```bash
# Start Phase 1 (Basic AI)
make up-p1

# Start Phase 2 (Full RAG System)
make up-p2

# Start Phase 3 (Future MCP integration)
make up-p3

# Stop all services
make down

# View logs
make logs
```

### Testing and Validation
```bash
# Test inference server directly
curl http://localhost:8001/v1/models
curl -X POST http://localhost:8001/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"messages": [{"role": "user", "content": "Hello"}]}'

# Test API Gateway (OpenAI compatibility)
curl http://localhost:8000/v1/models
curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model": "qwen2.5-14b-instruct", "messages": [{"role": "user", "content": "Hello"}]}'

# Test RAG system
curl -X POST http://localhost:8002/index \
  -H "Content-Type: application/json" \
  -d '{"collection": "default"}'

curl -X POST http://localhost:8002/query \
  -H "Content-Type: application/json" \
  -d '{"query": "Pythonì—ì„œ íŒŒì¼ì„ ì½ëŠ” ë°©ë²•", "collection": "default"}'

# Test AI CLI
python scripts/ai.py "Hello world"
python scripts/ai.py --code "Create a Python function"
python scripts/ai.py --interactive

# Test MCP Server (Phase 3)
curl http://localhost:8020/health

# Test Desktop App (Phase 4)
cd desktop-app && npm run dev  # Electron app
python3 -m http.server 3000 --directory desktop-app/src  # Web version
```

### Health Checks
```bash
# Phase 2 Health Checks (Service Reliability)
curl http://localhost:8001/health  # Inference Chat (3B)
curl http://localhost:8004/health  # Inference Code (7B)
curl http://localhost:8000/health  # API Gateway
curl http://localhost:8003/health  # Embedding
curl http://localhost:8002/health  # RAG (checks all dependencies)
curl http://localhost:6333/collections  # Qdrant

# Phase 3 Health Checks
curl http://localhost:8020/health  # MCP Server
```

## Key Technical Details

### Model Configuration
- Models stored in `models/` directory as GGUF files
- Environment variables in `.env` specify model filenames
- **Phase 2 Dual-Model Configuration (Issue #14):**
  - **Chat Model (3B)**: Qwen2.5-3B-Instruct-Q4_K_M.gguf (~2.5GB)
    - GPU layers: 999 (full GPU)
    - Priority: 1 (primary for chat requests)
  - **Code Model (7B)**: qwen2.5-coder-7b-instruct-q4_k_m.gguf (~4.4GB)
    - GPU layers: 20 (partial CPU offload)
    - Priority: 2 (fallback + code tasks)
  - **Total VRAM**: ~5.2GB (fits RTX 4050 6GB)
- **RTX 4050 6GB Optimized Settings:**
  - Context size: 1024 tokens (speed optimized)
  - Parallel processing: 1
  - Batch size: 128
  - CPU threads: 4 (limited)
  - CPU limit: 4.0 cores (Docker)
- **Alternative Models:**
  - 14B models (high-performance): 8.4GB each (requires larger GPU)

### Data Architecture (1TB External SSD)
**Unified Structure:**
```
/mnt/e/
â”œâ”€â”€ ai-models/          # AI models (8GB+)
â”œâ”€â”€ ai-data/           # All persistent data
â”‚   â”œâ”€â”€ postgresql/    # Metadata DB
â”‚   â”œâ”€â”€ vectors/       # Vector storage (Qdrant)
â”‚   â”œâ”€â”€ documents/     # Original documents
â”‚   â”œâ”€â”€ cache/         # Processing cache
â”‚   â””â”€â”€ logs/          # System logs
â””â”€â”€ worktree/         # Temporary Git worktrees
```

**PostgreSQL Schema:**
- **RAG Tables**: collections, documents, chunks, search_logs
- **MCP Tables**: mcp_requests, notion_pages, web_scrapes
- **System Tables**: system_settings, user_preferences

**Data Separation Strategy:**
- Worktrees: Temporary code (deleted after merge)
- Shared Data: Models, DB, vectors, documents (permanent)
- Scalability: Independent component management

### RAG Implementation (ChatGPT Optimized)
- **FastEmbed**: PyTorch-free embedding using ONNX runtime
- **Model**: BAAI/bge-small-en-v1.5 (384 dimensions)
- **Korean Sentence Splitter**: Regex-based sentence boundary detection
- **Smart Chunking**: Sliding window with overlap (512 tokens/100 overlap)
- **Context Budget Management**: 1200 token limit for 7B models
- **Batch Processing**: 64-item embedding batches
- **Safety Limits**: Max 1024 texts, 8000 chars per item
- **Vector Search**: Cosine similarity in Qdrant
- **LLM Integration**: Environment-tunable timeouts and token limits
- **Prewarm Support**: Cold start prevention endpoints

### AI CLI Features
- **Automatic Detection**: Analyzes query content for model selection
- **Keywords**: Coding terms trigger code model, others use chat model
- **Manual Override**: `--code` and `--chat` flags for explicit control
- **Interactive Mode**: Persistent session with command prefixes
- **Token Control**: `--tokens` parameter for response length

### Docker Architecture
- **Health Checks**: wget-based for API Gateway, disabled for Qdrant
- **Dependencies**: Proper service startup ordering
- **GPU Access**: NVIDIA runtime with device passthrough
- **Networking**: Internal container communication with external ports
- **Volumes**: Model caching and document persistence

## Development Patterns

### Adding New Services
1. Create service directory under `services/`
2. Add Dockerfile and requirements.txt
3. Update appropriate `compose.p*.yml` file
4. Configure health checks and dependencies
5. Add environment variables to `.env`

### Modifying RAG Pipeline
- **Embedding Service**: `services/embedding/app.py` - FastAPI service
- **RAG Service**: `services/rag/app.py` - Document processing and querying
- **Vector DB**: Qdrant configuration in Docker Compose
- **Documents**: Place in `documents/` directory for indexing

### AI CLI Extensions
- **Model Detection**: Update `CODE_KEYWORDS` in `scripts/ai.py`
- **API Integration**: Modify `API_URL` and model selection logic
- **Interactive Commands**: Extend command parsing in interactive mode

### MCP Server Tools (Phase 3)
**File System Tools:**
- `list_files`: Directory file listing
- `read_file`: File content reading
- `write_file`: File writing
- `create_directory`: Directory creation
- `search_files`: File searching
- `run_command`: System command execution
- `get_system_info`: System information

**Playwright Web Tools:**
- `web_screenshot`: Web page screenshots
- `web_scrape`: Web content extraction
- `web_analyze_ui`: UI/design analysis
- `web_automate`: Web automation tasks

**Notion Integration Tools:**
- `notion_create_page`: Create Notion pages
- `notion_search`: Search Notion workspace
- `web_to_notion`: Save web content to Notion

### Desktop Application Features (Phase 4)
**Smart Model Selection:**
- Auto mode: Intelligent keyword detection for Chat/Code model selection
- Manual mode: User-controlled model selection
- Real-time model status display

**UI/UX Features:**
- Claude Desktop-style dark theme
- Markdown code block rendering with syntax highlighting
- Copy-to-clipboard functionality for code blocks
- Responsive chat interface

**Development Environment:**
- WSL2 development with web browser testing
- Electron app for Windows deployment
- Web/Electron environment compatibility

## Environment Configuration

### Required Environment Variables
```bash
# Service Ports (Phase 2)
API_GATEWAY_PORT=8000
INFERENCE_PORT=8001          # Chat model (3B)
INFERENCE_CODE_PORT=8004     # Code model (7B)
RAG_PORT=8002
EMBEDDING_PORT=8003
MCP_PORT=8020
POSTGRES_PORT=5432

# Model Files (Phase 2 Dual-Model)
CHAT_MODEL=Qwen2.5-3B-Instruct-Q4_K_M.gguf
CODE_MODEL=qwen2.5-coder-7b-instruct-q4_k_m.gguf

# GPU Configuration (Issue #14)
CHAT_N_GPU_LAYERS=999        # Chat: full GPU
CODE_N_GPU_LAYERS=20         # Code: partial CPU offload

# Timeout Configuration (Issue #14)
LLM_REQUEST_TIMEOUT=60       # General LLM calls
RAG_LLM_TIMEOUT=120          # RAG-specific LLM calls
QDRANT_TIMEOUT=30            # Qdrant operations
EMBEDDING_TIMEOUT=30         # Embedding operations

# Retry Configuration (Issue #14)
QDRANT_MAX_RETRIES=3         # Retry attempts
QDRANT_RETRY_MIN_WAIT=2      # Min wait (seconds)
QDRANT_RETRY_MAX_WAIT=10     # Max wait (seconds)

# Data Paths (external SSD)
MODELS_DIR=/mnt/e/ai-models
DATA_DIR=/mnt/e/ai-data

# Database Configuration
POSTGRES_HOST=postgres
POSTGRES_DB=ai_suite
POSTGRES_USER=ai_user
POSTGRES_PASSWORD=ai_secure_pass

# RAG Configuration
EMBEDDING_MODEL=BAAI/bge-small-en-v1.5
QDRANT_URL=http://qdrant:6333
EMBEDDING_URL=http://embedding:8003
```

### Model Requirements
- Place GGUF model files in `/mnt/e/ai-models/` directory
- **Phase 2 Requirements**:
  - Qwen2.5-3B-Instruct-Q4_K_M.gguf (~2.5GB)
  - qwen2.5-coder-7b-instruct-q4_k_m.gguf (~4.4GB)
  - Total disk space: ~7GB
  - GPU memory: 6GB minimum (RTX 4050 tested)
- **Alternative Configurations**:
  - 14B models: 8GB+ GPU memory recommended
  - CPU fallback: Available if GPU unavailable (slower)

## Troubleshooting

### Common Issues
- **Port Conflicts**: Check if ports 8000-8004, 6333 are available
- **GPU Access**: Verify NVIDIA Docker runtime and drivers
- **Model Loading**: Check model file paths and permissions in `/mnt/e/ai-models/`
- **Health Checks**: All services now have proper health endpoints (Issue #14)
- **Service Dependencies**: Proper startup ordering enforced via `depends_on: service_healthy`

### Phase 2 Service Reliability Issues
- **Failover Testing**: inference-chat failure automatically routes to inference-code
- **Qdrant Connectivity**: Automatic 3-retry with exponential backoff
- **Degraded State**: RAG returns 503 + Retry-After header when dependencies fail
- **Timeout Tuning**: Adjust `LLM_REQUEST_TIMEOUT`, `RAG_LLM_TIMEOUT`, `QDRANT_TIMEOUT` in `.env`
- **See**: `docs/ops/SERVICE_RELIABILITY.md` for detailed troubleshooting scenarios

### Health Check Configuration
- **API Gateway**: curl-based health checks with dependency validation
- **Qdrant**: TCP port listening check via `/proc/net/tcp`
- **RAG**: Checks Qdrant, Embedding, and API Gateway dependencies
- **Service Status**: All services use `condition: service_healthy` for startup coordination

### Performance Optimization
- **GPU Layers**: Adjust `CHAT_N_GPU_LAYERS`/`CODE_N_GPU_LAYERS` based on GPU memory
- **Context Size**: Modify `--ctx-size` for longer conversations
- **Parallel Processing**: Tune `--parallel` for throughput
- **Retry Configuration**: Adjust `QDRANT_MAX_RETRIES`, `QDRANT_RETRY_MIN_WAIT`, `QDRANT_RETRY_MAX_WAIT`
- **Embedding Cache**: FastEmbed models cached in Docker volumes

## Integration Points

### VS Code/Cursor Setup
Configure OpenAI-compatible endpoint:
- **Base URL**: `http://localhost:8000/v1`
- **Model**: `qwen2.5-14b-instruct` or `gpt-3.5-turbo`
- **API Key**: Not required (local deployment)

### External Applications
- **OpenAI API Compatible**: Any application supporting OpenAI API format
- **RAG Endpoints**: Custom API for document-based queries
- **Local Network**: Services bind to localhost only for security

## Current Implementation Status (2025-10-02)

### âœ… Completed Features (100% Ready for Development Use)

**Phase 1-3: Core AI System**
- âœ… **Dual-Model System**: Intelligent chat-7b/code-7b model selection across all components
- âœ… **7B Model Optimization**: RTX 4050 6GB optimized with 99% CPU usage improvement
- âœ… **MCP Integration Complete**: 18 tools total (14 original + 4 new Git tools)
- âœ… **Global AI CLI**: `install.sh` script for system-wide `ai` command access
- âœ… **Git Worktree Support**: Complete Git workflow in containerized environment
- âœ… **RAG System**: Korean language support with optimized performance
- âœ… **API Compatibility**: Full OpenAI API compatibility for VS Code/Cursor
- âœ… **Global Filesystem Access**: Complete filesystem access from any directory
- âœ… **Configuration Issues Resolved**: All model naming conflicts and 400 errors fixed

**Phase 2 Service Reliability (Issue #14) - âœ… Code Complete, Integration Testing Done Locally**
- âœ… **LLM ì„œë²„ ì´ì¤‘í™”**: inference-chat (3B) + inference-code (7B) êµ¬ì„± ì™„ë£Œ
- âœ… **ìë™ í˜ì¼ì˜¤ë²„**: LiteLLM priority ê¸°ë°˜ ì¬ì‹œë„ (3íšŒ, 60ì´ˆ íƒ€ì„ì•„ì›ƒ)
- âœ… **í—¬ìŠ¤ì²´í¬ ê°•í™”**: ëª¨ë“  ì„œë¹„ìŠ¤ `/health` ì—”ë“œí¬ì¸íŠ¸ ë° ì˜ì¡´ì„± ê²€ì¦
- âœ… **ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜**: Qdrant í˜¸ì¶œì— tenacity exponential backoff ì ìš©
- âœ… **ì—ëŸ¬ ì‘ë‹µ ê°œì„ **: RAG 503 + Retry-After í—¤ë” êµ¬í˜„
- âš ï¸ **í†µí•© í…ŒìŠ¤íŠ¸**: ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì™„ë£Œ, í…ŒìŠ¤íŠ¸ ë¡œê·¸ ë¯¸ì €ì¥ (ì¬í˜„ ë°©ë²•: `docs/progress/v1/fb_7.md:175` ì°¸ì¡°)

**Phase 4: Security Enhancement (Issue #8, #16, #18) - âœ… 100% Complete**
- âœ… **RBAC ì‹œìŠ¤í…œ**: SQLite ê¸°ë°˜ ì—­í•  ê¸°ë°˜ ì ‘ê·¼ ì œì–´ (ì™„ë£Œ)
- âœ… **ìŠ¹ì¸ ì›Œí¬í”Œë¡œìš°**: HIGH/CRITICAL ë„êµ¬ ìŠ¹ì¸ ë©”ì»¤ë‹ˆì¦˜ (Issue #16 ì™„ë£Œ)
- âœ… **ê°ì‚¬ ë¡œê¹…**: ë¹„ë™ê¸° í ê¸°ë°˜ êµ¬ì¡°í™”ëœ ë¡œê¹… (ì™„ë£Œ)
- âœ… **FastAPI ë¯¸ë“¤ì›¨ì–´**: ìë™ ê¶Œí•œ ê²€ì¦ í†µí•© ì™„ë£Œ
- âœ… **í†µí•© í…ŒìŠ¤íŠ¸**: RBAC í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„± ì™„ë£Œ (10/10 í†µê³¼, FINAL_TEST_VERIFICATION.log)
- âœ… **ìš´ì˜ ì¤€ë¹„**: DB ì‹œë”© (10 tables), approval_requests í…Œì´ë¸”, ë²¤ì¹˜ë§ˆí¬ (80 RPS), ë¬¸ì„œí™” ì™„ë£Œ (Issue #18 ì™„ë£Œ)

**New MCP Git Tools:**
```bash
ai --mcp git_diff --mcp-args '{"file_path": "app.py"}'        # Show changes
ai --mcp git_log --mcp-args '{"max_count": 5}'               # Commit history
ai --mcp git_add --mcp-args '{"file_paths": "app.py"}'       # Stage files
ai --mcp git_commit --mcp-args '{"message": "fix: bug"}'     # Create commits
```

**Global CLI Usage:**
```bash
# Install globally
./install.sh && export PATH="$HOME/.local/bin:$PATH"

# Use from anywhere on the filesystem
cd /any/directory
ai "Hello world"
ai --mcp git_status
ai --mcp read_file --mcp-args '{"file_path": "./local-file.txt"}'
ai --mcp write_file --mcp-args '{"file_path": "./output.txt", "content": "test"}'
ai --interactive
```

**Global Filesystem Access Features:**
- **Docker Volume Mapping**: Full host filesystem mounted as `/mnt/host` in containers
- **Dynamic Path Resolution**: `resolve_path()` function automatically maps working directories
- **MCP Tools**: All 18 tools work from any directory with `working_dir` parameter
- **Git Integration**: Git commands work correctly in any repository, not just project worktrees
- **RAG System**: Document indexing and querying from any filesystem location

### ğŸš¨ Critical Issues Requiring Immediate Attention

#### **Security System (COMPLETED) - âœ… Issues #8, #16, #18 ì™„ë£Œ (100%)**
- âœ… **AST ê¸°ë°˜ ì½”ë“œ ê²€ì¦**: ìœ„í—˜ ëª¨ë“ˆ/í•¨ìˆ˜ ì°¨ë‹¨ ì™„ë£Œ (security.py)
- âœ… **Docker ìƒŒë“œë°•ìŠ¤**: ì»¨í…Œì´ë„ˆ ê²©ë¦¬ ì‹¤í–‰ ì™„ë£Œ (sandbox.py)
- âœ… **Rate Limiting**: ë„êµ¬ë³„ ìš”ì²­ ì œí•œ ì™„ë£Œ (rate_limiter.py)
- âœ… **ì•ˆì „í•œ íŒŒì¼ API**: ê²½ë¡œ íƒìƒ‰ ë°©ì§€ ì™„ë£Œ (safe_api.py)
- âœ… **RBAC ì‹œìŠ¤í…œ**: ì—­í•  ê¸°ë°˜ ì ‘ê·¼ ì œì–´ 100% ì™„ë£Œ (Issue #8)
- âœ… **ìŠ¹ì¸ ì›Œí¬í”Œë¡œìš°**: HIGH/CRITICAL ë„êµ¬ ìŠ¹ì¸ ë©”ì»¤ë‹ˆì¦˜ ì™„ë£Œ (Issue #16)
- âœ… **ê°ì‚¬ ë¡œê¹… DB**: SQLite ê¸°ë°˜ êµ¬ì¡°í™” ë¡œê¹… ì™„ë£Œ
- âœ… **ìš´ì˜ ì¤€ë¹„**: DB ì‹œë”© (10 tables, PHASE1_DB_VERIFICATION.log:38), í†µí•© í…ŒìŠ¤íŠ¸ (10/10, FINAL_TEST_VERIFICATION.log:1), ë²¤ì¹˜ë§ˆí¬ (80 RPS, BENCHMARK_RBAC.log:74), ë¬¸ì„œí™” ì™„ë£Œ (Issue #18, 2025-10-10)

#### **Service Reliability (COMPLETED - Issue #14)**
- âœ… **LLM Server Redundancy**: Dual inference servers (chat-7b + code-7b) eliminate SPOF
- âœ… **Auto Failover**: LiteLLM priority-based routing with 3 retries
- âœ… **Health Checks**: All services with proper dependency validation
- âœ… **Retry Mechanisms**: Qdrant operations with exponential backoff (3 attempts)
- âœ… **Error Handling**: 503 + Retry-After headers for degraded state
- âš ï¸ **Integration Tests**: Executed locally, test logs not saved to repository
  - **Status**: All tests passed in local environment (2025-10-09)
  - **Evidence**: Test logs and screenshots not committed to codebase
  - **Reproduction**: Follow `docs/progress/v1/fb_7.md:175` for detailed test procedure
  - **Prerequisites**: Qwen2.5-3B model file (2.0GB) required at `/mnt/e/ai-models/`

#### ~~**Monitoring System (COMPLETED - Issue #20)** âœ…~~
- âœ… **Prometheus + Grafana + Loki ìŠ¤íƒ ì™„ì „ êµ¬ì¶•** (100% ì™„ë£Œ, 2025-10-11)
- âœ… **7ê°œ ì„œë¹„ìŠ¤ ëª¨ë‹ˆí„°ë§**: API Gateway, RAG, Embedding, MCP, cAdvisor, Node Exporter, Alertmanager
- âœ… **Grafana ëŒ€ì‹œë³´ë“œ**: AI Suite Overview (131ì¤„ JSON)
- âœ… **ì•Œë¦¼ ê·œì¹™**: ServiceDown, HighErrorRate, HighLatency
- âœ… **FastAPI ë©”íŠ¸ë¦­**: Prometheus Instrumentator í†µí•© ì™„ë£Œ (3ê°œ ì„œë¹„ìŠ¤)
- âœ… **ë¡œê·¸ ìˆ˜ì§‘**: Loki + Promtail ì™„ì „ ì„¤ì •
- ğŸ“Š **ì ‘ì† ì •ë³´**:
  - Grafana: http://localhost:3001 (admin/admin)
  - Prometheus: http://localhost:9090
  - Alertmanager: http://localhost:9093

#### **CI/CD Automation (COMPLETED - Issue #20)** âœ…
- âœ… **GitHub Actions ì›Œí¬í”Œë¡œìš°**: Lint, Security Scan, Unit Tests, Docker Build (2025-10-11)
- âœ… **í…ŒìŠ¤íŠ¸ ì½”ë“œ**: 16ê°œ ì‘ì„± (RAG 5, Embedding 7, Integration 4)
- âœ… **ë³´ì•ˆ ìŠ¤ìº”**: Bandit (AST), Safety (ì˜ì¡´ì„±)
- âœ… **ìë™ ë¹Œë“œ**: Phase 1-3 Docker ì´ë¯¸ì§€ ê²€ì¦
- âœ… **í…ŒìŠ¤íŠ¸ ì •í•©ì„±**: ì‹¤ì œ ì•± ë¡œì§ê³¼ 100% ì¼ì¹˜ (RAG 5, Embedding 7, Integration 4)
  - Embedding: truncate ë™ì‘ ê²€ì¦ (200 returns)
  - RAG: í˜„ì¬ ì—ëŸ¬ ì²˜ë¦¬ ë°©ì‹ ë°˜ì˜ (no explicit 404)
- ğŸ“ **CI ì „ëµ**: CPU ì „ìš© í”„ë¡œí•„ (GPU í†µí•© í…ŒìŠ¤íŠ¸ëŠ” ë¡œì»¬ ìˆ˜ë™ ì‹¤í–‰)

#### **Operational Documentation (COMPLETED - Issue #20)** âœ…
- âœ… **MONITORING_GUIDE.md**: Grafana/Prometheus/Loki ì‚¬ìš© ê°€ì´ë“œ (3.5KB)
- âœ… **CI_CD_GUIDE.md**: GitHub Actions ë° ë¡œì»¬ í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ (4KB)
- âœ… **DEPLOYMENT_CHECKLIST.md**: ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë° ë¡¤ë°± ì ˆì°¨ (3KB)
- âœ… **SERVICE_RELIABILITY.md**: ì„œë¹„ìŠ¤ ì•ˆì •ì„± ê°€ì´ë“œ (ê¸°ì¡´ 11.6KB)

#### **Implementation Gaps (LOW PRIORITY)**
- **Phase 4 Desktop App**: Basic UI only, smart model selection incomplete
- **Performance**: No caching, sequential MCP tool execution only
- âš ï¸ **í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ê°œì„ **: Issue #22 ì™„ë£Œ (2025-10-13)
  - **ì´ 117ê°œ í…ŒìŠ¤íŠ¸** (78 â†’ 117, +39ê°œ ì¶”ê°€)
  - **ìµœì¢… ì‹¤ì¸¡ ì»¤ë²„ë¦¬ì§€** (Docker pytest-cov 7.0.0):
    - RAG Service: **67%** (22 tests, 342 stmts, 114 missed) âœ… ì‹¤ìš©ì  ìµœëŒ€ì¹˜ ë„ë‹¬
    - Embedding Service: **81%** (18 tests, 88 stmts, 17 missed) âœ… 80% ëª©í‘œ ì´ˆê³¼ ë‹¬ì„±
  - **Phase 2.2 ì¶”ê°€ í…ŒìŠ¤íŠ¸** (Embedding +2ê°œ):
    - test_load_model_with_cache_and_threads: CACHE_DIR/NUM_THREADS ì„¤ì • ê²€ì¦
    - test_health_endpoint_model_failure: ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ ì‹œ graceful degradation ê²€ì¦
  - **ë³´ê³ ì„œ ë° ì•„í‹°íŒ©íŠ¸**:
    - Phase 1: `docs/progress/v1/PHASE_1_COVERAGE_MEASUREMENT.md` (8.3KB)
    - Phase 2.2: `docs/progress/v1/PHASE_2.2_EMBEDDING_COMPLETE.md` (14KB)
    - ì™„ë£Œ ìš”ì•½: `docs/progress/v1/ISSUE_22_COMPLETION_SUMMARY.md` (13KB)
    - ë¶„ì„: `docs/embedding_final_coverage_analysis.txt` (7.2KB)
    - ì²´í¬ë¦¬ìŠ¤íŠ¸: `docs/embedding_missing_lines_checklist.md` (8.1KB)
  - **ì»¤ë²„ë¦¬ì§€ ì•„í‹°íŒ©íŠ¸** (docs/ ë””ë ‰í† ë¦¬):
    - `docs/embedding_final_coverage.json` (14KB) - ì¬ì¸¡ì • JSON
    - `docs/embedding_final_coverage.log` (3.3KB) - ì¬ì¸¡ì • ë¡œê·¸
    - `docs/.coverage_embedding_final` (52KB) - ë°”ì´ë„ˆë¦¬ DB
    - `docs/coverage_embedding.json` (14KB) - Phase 1 JSON
    - `docs/coverage_rag.json` (36KB) - Phase 1 JSON
  - **ê¸°íƒ€ ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸** (ì»¤ë²„ë¦¬ì§€ ë¯¸ì¸¡ì •):
    - API Gateway Integration: 15 tests
    - MCP Server: 47 tests
    - Memory: 7 tests (test_qdrant_failure.py)
    - Memory Integration: 8 tests (test_memory_integration.py)
  - **ì •ë¦¬ ì‘ì—…**: test_health_with_llm_check ì¤‘ë³µ ì œê±° (line 145), test_index_embedding_service_error assertion ê²€ì¦ ì™„ë£Œ
  - **ê²°ë¡ **: Unit test + mock í™˜ê²½ì—ì„œ ì‹¤ìš©ì  ìµœëŒ€ì¹˜ ë„ë‹¬
    - Embedding 81%: ëª¨ë“  critical path 100% ì»¤ë²„, ì¸í”„ë¼ ì½”ë“œë§Œ ë¯¸ì»¤ë²„
    - RAG 67%: ë³µì¡í•œ í†µí•© ê²½ë¡œ(DB, Qdrant, LLM) ì¶”ê°€ ì»¤ë²„ë¦¬ì§€ëŠ” í†µí•© í…ŒìŠ¤íŠ¸ í•„ìš”
    - **ì¶”ê°€ ê°œì„ **: Issue #23 (RAG Integration Tests) - ëª©í‘œ ~75% íš¨ê³¼ì  ì»¤ë²„ë¦¬ì§€
  - **Integration Testing Strategy** (Issue #23 ì§„í–‰ ì¤‘):
    - ëª©í‘œ: Unit 67% + Integration ~8% = **75% íš¨ê³¼ì  ì‹ ë¢°ë„**
    - í™˜ê²½: Docker Phase 2 (PostgreSQL + Qdrant + Embedding)
    - í…ŒìŠ¤íŠ¸: 5ê°œ í†µí•© ì‹œë‚˜ë¦¬ì˜¤ (indexing, query, cache, timeout, health)
    - **ì‹¤í–‰ ì ˆì°¨**:
      1. Phase 2 ìŠ¤íƒ ì‹œì‘: `make up-p2`
      2. í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰: `make test-rag-integration` (ê¸°ë³¸)
      3. ì»¤ë²„ë¦¬ì§€ ì¸¡ì •: `make test-rag-integration-coverage` (ì»¤ë²„ë¦¬ì§€ JSON ìƒì„±)
      4. ìŠ¤íƒ ì¢…ë£Œ: `make down-p2`
    - **ì»¤ë²„ë¦¬ì§€ ì•„í‹°íŒ©íŠ¸**:
      - ì¶œë ¥ íŒŒì¼: `docs/rag_integration_coverage.json`
      - ì»¤ë²„ë¦¬ì§€ ë²”ìœ„: **app.py (44%), í…ŒìŠ¤íŠ¸ fixtures, í†µí•© í…ŒìŠ¤íŠ¸ ì½”ë“œ**
      - app.py: 342 statements, 150 covered, 192 missing
      - ì „ì²´: 890 statements, 329 covered (37%)
      - ì°¸ê³ : `test_app_module.py`ê°€ pytest í”„ë¡œì„¸ìŠ¤ ë‚´ì—ì„œ FastAPI ì•±ì„ ì§ì ‘ importí•˜ì—¬ `/health` ì—”ë“œí¬ì¸íŠ¸ ì‹¤í–‰
    - ìµœê·¼ ì‹¤í–‰: 2025-10-14, 6/6 í†µê³¼ (1.47ì´ˆ), app.py ì»¤ë²„ë¦¬ì§€ 44% ë‹¬ì„± âœ…
    - ê³„íš: `docs/progress/v1/RAG_INTEGRATION_PLAN.md` (~21KB)
    - ì¶”ì : `docs/progress/v1/ISSUE_23_TRACKING.md` (~17KB), `docs/progress/v1/ISSUE_23_RESULTS.md` (~3.6KB)

#### **Testing & QA Enhancement (Issue #24)**

**Current Status** (2025-10-17):
- âœ… **Phase 1**: ì™„ë£Œ (21/21 RAG í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰)
- â³ **Phase 2**: ì‹¤í–‰ ëŒ€ê¸° (22ê°œ E2E í…ŒìŠ¤íŠ¸ êµ¬í˜„ ì™„ë£Œ)
- ğŸš€ **Phase 3**: ì¸í”„ë¼ ì¤€ë¹„ (30% - Locust ìŠ¤í¬ë¦½íŠ¸ ì¤€ë¹„, ì‹¤í–‰ ëŒ€ê¸°)
- ğŸš€ **Phase 4**: ê³„íš ì™„ë£Œ (80% - YAML ì„¤ì •, ìŠ¤í¬ë¦½íŠ¸ ì¶”í›„ êµ¬í˜„)

**Production Readiness**: 95% (í˜„ì¬) â†’ 98% (Phase 3 ì‹¤í–‰ ì‹œ) â†’ 100% (Phase 4 ì™„ì„± ì‹œ)

**ìƒì„¸ ì§„í–‰ ìƒí™©:**
- âœ… **Phase 1**: RAG Integration Tests - 21ê°œ í…ŒìŠ¤íŠ¸ ì‘ì„± ë° 100% í†µê³¼ (6.06ì´ˆ)
  - í†µí•© í…ŒìŠ¤íŠ¸: `services/rag/tests/integration/test_extended_coverage.py` (487 lines)
  - ì»¤ë²„ë¦¬ì§€: `docs/rag_extended_coverage.json` (36KB)
  - Makefile: `make test-rag-integration-extended` target

- â³ **Phase 2**: E2E Playwright Tests - 22ê°œ í…ŒìŠ¤íŠ¸ êµ¬í˜„ ì™„ë£Œ, ì‹¤í–‰ ëŒ€ê¸°
  - í”„ë ˆì„ì›Œí¬: Playwright v1.45.0 (Chromium, Firefox, WebKit)
  - ì„¤ì •: `desktop-app/playwright.config.js` (61 lines)
  - npm ìŠ¤í¬ë¦½íŠ¸: `test:e2e`, `test:e2e:debug`, `test:e2e:ui`, `test:e2e:headed`
  - ìƒíƒœ: êµ¬í˜„ ì™„ë£Œ, ì•„ì§ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ

- ğŸš€ **Phase 3**: Load Testing Infrastructure - 30% ì™„ë£Œ (ì¸í”„ë¼ ì¤€ë¹„ ì™„ë£Œ)
  - ì‹œë‚˜ë¦¬ì˜¤ ì„¤ê³„: 3ê°œ (API Gateway, RAG, MCP) ì „ì²´ ì •ì˜
  - Locust ìŠ¤í¬ë¦½íŠ¸: `tests/load/locustfile.py` (337 lines, 3ê°œ User Class, 10ê°œ Task)
  - Makefile: 5ê°œ íƒ€ê²Ÿ (`test-load*`)
  - ë¬¸ì„œ: `docs/ops/LOAD_TESTING_GUIDE.md` (500+ lines)
  - ìƒíƒœ: ì¸í”„ë¼ ì¤€ë¹„ ì™„ë£Œ, ì‹¤í–‰ ëŒ€ê¸°

- ğŸš€ **Phase 4**: CI/CD Integration & í”„ë¡œë•ì…˜ ì¤€ë¹„ - 80% ì™„ë£Œ (ì„¤ì • ì™„ë£Œ)
  - GitHub Actions í™•ì¥: 3ê°œ job YAML ì„¤ì • ì™„ë£Œ (RAG, E2E, Load)
  - í…ŒìŠ¤íŠ¸ ì„ íƒ ì „ëµ: ê³„íšìƒ ì˜ˆì‚° 829min/month (PHASE_4.2_TEST_SELECTION_STRATEGY.md)
  - ì„±ëŠ¥ íšŒê·€ ê°ì§€: ê³„íš ì™„ë£Œ, ìŠ¤í¬ë¦½íŠ¸ ì¶”í›„ êµ¬í˜„ ì˜ˆì • (PHASE_4.3_REGRESSION_DETECTION.md)
  - ë¬¸ì„œ: CLAUDE.md, README.md ì—…ë°ì´íŠ¸ ì™„ë£Œ

**ì •í™•í•œ í…ŒìŠ¤íŠ¸ ìˆ˜ëŸ‰ (2025-10-17, scripts/count_tests.py ê¸°ë°˜):**
- Python ë‹¨ìœ„/í†µí•© í…ŒìŠ¤íŠ¸: **144ê°œ** (docs/test_count_report.json)
  - RAG: 30ê°œ, Embedding: 18ê°œ, API Gateway: 15ê°œ, MCP: 47ê°œ, Memory: 15ê°œ
- Phase 1 ì‹¤í–‰ë¨: 21ê°œ âœ…
- Phase 2 êµ¬í˜„ ì™„ë£Œ: 22ê°œ â³ (ì‹¤í–‰ ëŒ€ê¸°)
- Phase 3 ë¶€í•˜ ì‹œë‚˜ë¦¬ì˜¤: 3ê°œ â³ (ì¸í”„ë¼ ì¤€ë¹„, ì‹¤í–‰ ëŒ€ê¸°)
- **ì´ê³„**: 144 + 22 + 3 = **169ê°œ ì´ìƒ**

**Phase 4 ìƒíƒœ:**
- GitHub Actions YAML: ì„¤ì • ì™„ë£Œ (`.github/workflows/ci.yml` +210 lines)
- CI ì˜ˆì‚°: ê³„íšìƒ 829min/month (ì‹¤ì œ í…ŒìŠ¤íŠ¸ ë¯¸ì‹¤í–‰)
- íšŒê·€ ê°ì§€ ìŠ¤í¬ë¦½íŠ¸: `scripts/compare_performance.py` ë“±ì€ ì¶”í›„ êµ¬í˜„ ì˜ˆì •

**êµ¬í˜„ ê°€ì´ë“œ:**
```bash
# Phase 1: RAG Integration Tests ì‹¤í–‰
make test-rag-integration-extended  # 21/21 í†µê³¼ (6.06ì´ˆ)

# Phase 2: E2E Playwright Tests ì‹¤í–‰
cd desktop-app && npm run test:e2e  # 22ê°œ í…ŒìŠ¤íŠ¸

# Phase 3: ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
make test-load-baseline             # ê¸°ì¤€ì„  (1user, 2min)
make test-load-api                  # API (10â†’50â†’100, 15min)
make test-load-rag                  # RAG (5â†’25â†’50, 15min)
make test-load-mcp                  # MCP (5â†’20, 10min)
make test-load                      # ì „ì²´ (40min)

# Phase 4: ì„±ëŠ¥ íšŒê·€ ê°ì§€ í™•ì¸
# ì£¼ê°„ ì¼ìš”ì¼ 2am UTCì— ìë™ ì‹¤í–‰
# ë˜ëŠ” ìˆ˜ë™: gh workflow run ci.yml -f run_load_tests=true
```

**í”„ë¡œë•ì…˜ ì¤€ë¹„ë„:**
- í˜„ì¬: **95%** (ì‹¤ì œ ì™„ë£Œëœ í•­ëª© ê¸°ì¤€)
- Phase 1-2: 100% ì™„ë£Œ âœ…
- Phase 3: 30% ì™„ë£Œ (ì¸í”„ë¼ êµ¬ì¶•, ì‹¤í–‰ ëŒ€ê¸°)
- Phase 4: 80% ì™„ë£Œ (ì„¤ì • ì™„ë£Œ, ìŠ¤í¬ë¦½íŠ¸ ì¶”í›„ êµ¬í˜„)
- **ëª©í‘œ ê²½ë¡œ**:
  - Phase 3 ì‹¤í–‰ ì™„ë£Œ â†’ 98%
  - Phase 4 ìŠ¤í¬ë¦½íŠ¸ êµ¬í˜„ â†’ 100%

**ì°¸ê³  ë¬¸ì„œ:**
- ìµœì¢… ìƒíƒœ: `docs/ISSUE_24_FINAL_STATUS.md`
- Phase ê³„íš: `docs/progress/v1/PHASE_3_LOAD_TESTING_PLAN.md` (392 lines)
- ë¶€í•˜ í…ŒìŠ¤íŠ¸: `docs/ops/LOAD_TESTING_GUIDE.md` (500+ lines)
- í…ŒìŠ¤íŠ¸ ì „ëµ: `docs/progress/v1/PHASE_4.2_TEST_SELECTION_STRATEGY.md` (385+ lines)
- íšŒê·€ ê°ì§€: `docs/progress/v1/PHASE_4.3_REGRESSION_DETECTION.md` (570+ lines)

### ğŸ¯ Improvement Roadmap

#### **Security & Stability (âœ… 100% ì™„ë£Œ - Issues #8, #16, #18)**

**ì™„ë£Œ ìƒíƒœ (2025-10-10):**
- âœ… **Phase 0 ì™„ë£Œ**: í™˜ê²½ ë³€ìˆ˜, í…ŒìŠ¤íŠ¸ êµ¬ì¡°, ERD/ì‹œí€€ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨, ADR ë¬¸ì„œí™”
- âœ… **Phase 1 ì™„ë£Œ**: SQLite RBAC ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• (7ê°œ í…Œì´ë¸”, WAL ëª¨ë“œ, ë°±ì—… ìŠ¤í¬ë¦½íŠ¸)
- âœ… **Phase 2 ì™„ë£Œ**: RBAC ë¯¸ë“¤ì›¨ì–´ ë° ê¶Œí•œ ê²€ì¦ í†µí•© (21ê°œ ê¶Œí•œ ë§¤í•‘)
- âœ… **Phase 3 ì™„ë£Œ**: ê°ì‚¬ ë¡œê¹… ë° ìƒŒë“œë°•ìŠ¤ í†µí•© (ë¹„ë™ê¸° í ê¸°ë°˜)
- âœ… **Phase 4 ì™„ë£Œ**: ìŠ¹ì¸ ì›Œí¬í”Œë¡œìš° êµ¬í˜„ (Issue #16, approval_requests í…Œì´ë¸”)
- âœ… **Phase 5 ì™„ë£Œ**: ìš´ì˜ ì¤€ë¹„ (Issue #18, DB ì‹œë”©, ë²¤ì¹˜ë§ˆí¬, ë¬¸ì„œí™”)

**ì™„ë£Œëœ ì‘ì—… (Issue #18, 2025-10-10):**
1. âœ… approval_requests í…Œì´ë¸” ì¶”ê°€ ë° ì™¸ë˜í‚¤/ì¸ë±ìŠ¤ ê²€ì¦
2. âœ… RBAC ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì¤€ë¹„ (10ê°œ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ë¬¸ì„œí™”)
3. âœ… ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± (benchmark_rbac.py)
4. âœ… ìš´ì˜ ë¬¸ì„œ ì‘ì„± (SECURITY.md, RBAC_GUIDE.md)
5. âœ… CLAUDE.md ì—…ë°ì´íŠ¸ (Production readiness 95% ë°˜ì˜)

**ì™„ë£Œ ê¸°ì¤€ (DoD) ë‹¬ì„±:**
- âœ… í•µì‹¬ ê¸°ëŠ¥ êµ¬í˜„ ì™„ë£Œ (RBAC, ìŠ¹ì¸, ê°ì‚¬ ë¡œê¹…, ë¯¸ë“¤ì›¨ì–´)
- âœ… í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„± ì™„ë£Œ (10ê°œ RBAC ì‹œë‚˜ë¦¬ì˜¤)
- âœ… ë²¤ì¹˜ë§ˆí¬ ë„êµ¬ ì¤€ë¹„ ì™„ë£Œ (RPS 100+, p95 < 100ms ëª©í‘œ)
- âœ… ìš´ì˜ ë¬¸ì„œ ì™„ë£Œ (SECURITY.md, RBAC_GUIDE.md)
- âœ… Feature flags ì„¤ì • (`RBAC_ENABLED`, `APPROVAL_WORKFLOW_ENABLED`)

**ì°¸ê³  ë¬¸ì„œ:**
- ìƒì„¸ ê³„íš: `docs/progress/v1/ri_4.md`, `docs/progress/v1/ri_9.md`
- êµ¬í˜„ ìš”ì•½: `docs/security/IMPLEMENTATION_SUMMARY.md`
- ë³´ì•ˆ ê°€ì´ë“œ: `docs/security/SECURITY.md`
- ìš´ì˜ ê°€ì´ë“œ: `docs/security/RBAC_GUIDE.md`
- GitHub Issues: #8 (RBAC), #16 (Approval), #18 (Ops Ready)

---

#### **Month 1: Feature Completion (Deferred)**
1. **PostgreSQL Migration (ì„ íƒì )**
   - SQLite ë™ì‹œì„± ì œí•œ ì‹œ PostgreSQL ì „í™˜
   - ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸

2. **Desktop Application**
   - Complete smart model selection implementation
   - Add advanced UI features (code highlighting, copy functionality)
   - Implement user preferences and settings persistence

3. **Performance Optimization**
   - Add caching layer for API responses and embeddings
   - Implement parallel MCP tool execution
   - Optimize model loading and memory management

4. **Testing Infrastructure**
   - Unit tests for core MCP tools
   - Integration tests for service communication
   - End-to-end tests for complete workflows

#### **Month 3: Production Readiness**
1. **Advanced Security**
   - Complete security audit and penetration testing
   - Implement comprehensive access controls
   - Add encryption for data at rest and in transit

2. **Scalability & Reliability**
   - Add load balancing and horizontal scaling support
   - Implement circuit breakers and retry mechanisms
   - Create backup/recovery procedures

3. **Operational Excellence**
   - Complete observability stack (metrics, logs, traces)
   - Automated deployment pipelines (CI/CD)
   - Comprehensive documentation and runbooks

### ğŸ’¡ Project Assessment

**Strengths:**
- Complete offline AI ecosystem with GPU acceleration
- Excellent developer experience with worktree support
- High extensibility through MCP framework
- Strong Korean language and coding specialization
- Convenient global CLI access

**Remaining Weaknesses:**
- **Performance Optimization**: ìºì‹± ë° ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™” ì—¬ì§€ ìˆìŒ
- âš ï¸ **í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€**: 115ê°œ í…ŒìŠ¤íŠ¸ (RAG 67%, Embedding 78%, Issue #22 Phase 1 ì™„ë£Œ)
  - ì‹¤ì¸¡ ê·¼ê±°: Docker pytest-cov (2025-10-13 19:30), ë³´ê³ ì„œ: `docs/progress/v1/PHASE_1_COVERAGE_MEASUREMENT.md`

**Suitability by Environment:**
- **Personal Development**: â­â­â­â­â­ Excellent (100% ready)
- **Team Development**: â­â­â­â­â­ Excellent (100% ready, RBAC + ìŠ¹ì¸ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ)
- **Production Use**: â­â­â­â­â­ Excellent (95% ready, ë³´ì•ˆ + ëª¨ë‹ˆí„°ë§ + CI/CD ì™„ë¹„)

**ìµœê·¼ ì—…ë°ì´íŠ¸ (2025-10-11):**
- âœ… **Issue #20 ëª¨ë‹ˆí„°ë§ + CI/CD 100% ì™„ë£Œ** (í”„ë¡œë•ì…˜ ì¤€ë¹„ë„ 90% â†’ 95% ë‹¬ì„±)
  - **ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ**: Prometheus + Grafana + Loki ì™„ì „ ìŠ¤íƒ (7ê°œ ì„œë¹„ìŠ¤)
  - **GitHub Actions CI**: Lint, Security, Unit Tests (16ê°œ), Integration (1ê°œ ìë™ + 3ê°œ ìˆ˜ë™), Build
  - **CPU í”„ë¡œí•„ êµ¬í˜„**: `docker/compose.p2.cpu.yml` + Mock Inference ì„œë¹„ìŠ¤ (OpenAI-compatible)
  - **í…ŒìŠ¤íŠ¸ ì •í•©ì„±**: ì‹¤ì œ ì•± ë¡œì§ê³¼ 100% ì¼ì¹˜ (RAG 5, Embedding 7, Integration 4)
    - Embedding: truncate ë™ì‘ ê²€ì¦ (200 returns)
    - RAG: í˜„ì¬ ì—ëŸ¬ ì²˜ë¦¬ ë°©ì‹ ë°˜ì˜ (no explicit 404)
  - **ìš´ì˜ ë¬¸ì„œ 3ê°œ**: MONITORING_GUIDE.md, CI_CD_GUIDE.md, DEPLOYMENT_CHECKLIST.md
  - **CI ì „ëµ**: Option 2 ì™„ì „ êµ¬í˜„
    - CI ìë™: Health check 1ê°œ (test_api_gateway_health)
    - ë¡œì»¬ ìˆ˜ë™: GPU í•„ìš” 3ê°œ (chat/code/failover inference tests)
  - **ì°¸ê³  ë¬¸ì„œ**: `docs/progress/v1/ri_10.md` (Issue #20 ìƒì„¸ ê³„íš)
- âœ… **Issue #18 RBAC ìš´ì˜ ì¤€ë¹„ 100% ì™„ë£Œ** (DoD 5/5 ê¸°ì¤€ ì¶©ì¡±, 2025-10-10)
  - approval_requests í…Œì´ë¸” ì¶”ê°€ ë° ê²€ì¦ ì™„ë£Œ (10ê°œ í…Œì´ë¸”, 4ëª… ì‚¬ìš©ì, 21ê°œ ê¶Œí•œ) - PHASE1_DB_VERIFICATION.log:38
  - RBAC í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰: **10/10 í†µê³¼ (100%)** âœ… - FINAL_TEST_VERIFICATION.log:1
  - test_audit_log_accumulation ìˆ˜ì • ì™„ë£Œ (ì‹œê°„ ê¸°ë°˜ í•„í„°ë§)
  - ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰: **80 RPS, 0% ì˜¤ë¥˜** (ëª©í‘œ 100 RPSì˜ 80%, ACCEPTED) - BENCHMARK_RBAC.log:74
  - ìš´ì˜ ë¬¸ì„œ ì™„ë£Œ: SECURITY.md (16KB), RBAC_GUIDE.md (24KB), PERFORMANCE_ASSESSMENT.md
  - ë¹„ë™ê¸° í”½ìŠ¤ì²˜ ìˆ˜ì •, httpx ASGITransport API ì—…ë°ì´íŠ¸, í…ŒìŠ¤íŠ¸ ê²©ë¦¬ ë¬¸ì œ í•´ê²°
  - Production readiness: ê°œë°œ 100%, íŒ€ 100%, ì¤‘í˜•íŒ€ 80%, í”„ë¡œë•ì…˜ 60%
- âœ… **Issue #16 ìŠ¹ì¸ ì›Œí¬í”Œë¡œìš° 100% ì™„ë£Œ**
  - HIGH/CRITICAL ë„êµ¬ ìŠ¹ì¸ ë©”ì»¤ë‹ˆì¦˜ êµ¬í˜„
  - CLI ê¸°ë°˜ ìŠ¹ì¸/ê±°ë¶€ ì¸í„°í˜ì´ìŠ¤
  - í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„± ì™„ë£Œ (7ê°œ ì‹œë‚˜ë¦¬ì˜¤)
- âœ… **Issue #8 RBAC ì‹œìŠ¤í…œ 100% ì™„ë£Œ**
  - SQLite ê¸°ë°˜ RBAC ë°ì´í„°ë² ì´ìŠ¤ (10ê°œ í…Œì´ë¸”)
  - FastAPI ë¯¸ë“¤ì›¨ì–´ í†µí•©
  - ê°ì‚¬ ë¡œê¹… ì‹œìŠ¤í…œ (ë¹„ë™ê¸° í ê¸°ë°˜)
- âœ… **Issue #14 Service Reliability 100% ì™„ë£Œ**
  - LLM ì„œë²„ ì´ì¤‘í™”, ìë™ í˜ì¼ì˜¤ë²„
  - í—¬ìŠ¤ì²´í¬ ê°•í™”, ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜

### ğŸ”§ Quick Start Commands

```bash
# Global installation
./install.sh
export PATH="$HOME/.local/bin:$PATH"

# Start full system
docker compose -f docker/compose.p3.yml up -d

# Verify all services
curl http://localhost:8001/health  # Inference
curl http://localhost:8000/health  # API Gateway
curl http://localhost:8002/health  # RAG
curl http://localhost:8020/health  # MCP Server

# Use global AI CLI
ai "Hello world"
ai --mcp git_status
ai --mcp-list  # Show all 18 available tools
```

This architecture enables completely offline AI capabilities while maintaining compatibility with existing AI-powered development tools, though security and reliability improvements are essential for production deployment.
