# Phase 1 κµ¬ν„ μ™„λ£ μƒνƒ λ° μ κ²€μ‚¬ν•­

## π“‹ ν„μ¬ μ™„λ£λ μ‘μ—… (2025-09-22 21:13)

### β… μ„±κ³µμ μΌλ΅ μ™„λ£λ ν•­λ©

1. **λ¨λΈ λ‹¤μ΄λ΅λ“ μ™„λ£**
   - `qwen2.5-14b-instruct-q4_k_m.gguf` (8.4GB) - μΌλ° λ€ν™”ν• λ¨λΈ
   - `qwen2.5-coder-14b-instruct-q4_k_m.gguf` (8.4GB) - μ½”λ”© μ „μ© λ¨λΈ
   - μ΄ 17GB λ¨λΈ νμΌ μ¤€λΉ„ μ™„λ£

2. **ν™κ²½ μ„¤μ • μ™„λ£**
   - λΈλμΉ: `issue-1` μ‚¬μ© μ¤‘
   - `.env` νμΌ μƒμ„± λ° λ¨λΈλ… μ„¤μ • μ™„λ£
   - λ””λ ‰ν† λ¦¬ κµ¬μ΅°: `docker/`, `services/api-gateway/` μƒμ„±

3. **Docker Compose κµ¬μ„± μ™„λ£**
   - `docker/compose.p1.yml` μ‘μ„±
   - GPU ν¨μ¤μ¤λ£¨ μ„¤μ • (RTX 4050 λ€μ‘)
   - llama.cpp + LiteLLM μ΅°ν•© κµ¬μ„±

4. **μ„λΉ„μ¤ μ‹¤ν–‰ μ„±κ³µ**
   - `make up-p1` λ…λ ΉμΌλ΅ μ •μƒ μ‹¤ν–‰
   - μ¶”λ΅  μ„λ²„ (ν¬νΈ 8001): β… μ •μƒ λ™μ‘
   - API Gateway (ν¬νΈ 8000): β οΈ μ„¤μ • λ¬Έμ  μμ

### β… κ²€μ¦ μ™„λ£λ κΈ°λ¥

**llama.cpp μ¶”λ΅  μ„λ²„ (ν¬νΈ 8001)**
```bash
# λ¨λΈ λ©λ΅ ν™•μΈ (μ„±κ³µ)
curl -s http://localhost:8001/v1/models

# μ±„ν… μ™„λ£ API ν…μ¤νΈ (μ„±κ³µ)
curl -X POST http://localhost:8001/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"messages": [{"role": "user", "content": "μ•λ…•ν•μ„Έμ”!"}], "max_tokens": 100}'
```

**μ‹¤μ  μ‘λ‹µ μμ‹:**
> "λ¬Όλ΅ μ΄μ£ ! μ–΄λ–¤ μΆ…λ¥μ ν•¨μλ¥Ό μ›ν•μ‹λ”μ§€ μΆ€ λ” μμ„Έν μ„¤λ…ν•΄μ£Όμ‹¤ μ μλ‚μ”?"

---

## β οΈ ν•΄κ²°ν•΄μ•Ό ν•  λ¬Έμ μ 

### 1. LiteLLM API Gateway (ν¬νΈ 8000) λ¬Έμ 
**μ¦μƒ:**
- `curl http://localhost:8000/v1/models` β†’ Error
- API Gateway μ»¨ν…μ΄λ„κ°€ ν¬νΈ 4000μ—μ„ μ‹¤ν–‰λμ§€λ§ 8000μΌλ΅ λ§¤ν•‘ μ• λ¨

**μ‹λ„ν• ν•΄κ²°λ°©λ²•:**
1. ν™κ²½λ³€μ `LITELLM_PORT=8000` β†’ `PORT=8000`λ΅ λ³€κ²½
2. LiteLLM μ„¤μ •μ—μ„ `model: "openai/gpt-3.5-turbo"` β†’ `model: "llamacpp/local-chat"`λ΅ λ³€κ²½
3. `api_base: "http://inference:8001/v1"` β†’ `http://inference:8001"`λ΅ μμ •

**ν„μ¬ μƒνƒ:**
- LiteLLMμ΄ ν¬νΈ 4000μ—μ„ μ‹¤ν–‰ μ¤‘
- μ»¨ν…μ΄λ„ κ°„ ν†µμ‹  λ¬Έμ  κ°€λ¥μ„±

### 2. ν™κ²½λ³€μ κ²½κ³ 
```
The "CHAT_MODEL" variable is not set. Defaulting to a blank string.
```
- `.env` νμΌμ€ μ΅΄μ¬ν•μ§€λ§ Docker Composeμ—μ„ μΈμ‹ λ»ν•¨

---

## π”§ λ‹¤μ μ„Έμ…μ—μ„ μ°μ„  ν•΄κ²°ν•  μ‚¬ν•­

### 1. LiteLLM API Gateway μμ • (μ°μ„ μμ„: λ†’μ)

**ν™•μΈν•  μ„¤μ • νμΌλ“¤:**
- `docker/compose.p1.yml` - ν¬νΈ λ§¤ν•‘ λ° ν™κ²½λ³€μ
- `services/api-gateway/config.p1.yaml` - LiteLLM λ¨λΈ μ„¤μ •

**ν•΄κ²° λ°©ν–¥:**
1. LiteLLM ν¬νΈ μ„¤μ • μ¬ν™•μΈ
2. llamacpp provider μ„¤μ • μ •ν™•μ„± κ²€μ¦
3. λ„¤νΈμ›ν¬ μ—°κ²° ν…μ¤νΈ

### 2. ν™κ²½λ³€μ μΈμ‹ λ¬Έμ  ν•΄κ²°

**ν•΄κ²° λ°©λ²•:**
```bash
# .env νμΌ ν™•μΈ
cat .env

# Docker Composeμ—μ„ ν™κ²½λ³€μ μ§μ ‘ μ „λ‹¬ λ°©μ‹ κ²€ν† 
```

### 3. μ™„μ „ν• API ν…μ¤νΈ μν–‰

**ν…μ¤νΈν•  μ—”λ“ν¬μΈνΈ:**
```bash
# API Gatewayλ¥Ό ν†µν• ν…μ¤νΈ (λ©ν‘)
curl http://localhost:8000/v1/models
curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model": "local-chat", "messages": [{"role": "user", "content": "Hello"}]}'

# VS Code/Cursor μ—°λ™ ν…μ¤νΈ
# http://localhost:8000/v1 μ„¤μ •
```

---

## π“ μ£Όμ” νμΌ μ„μΉ

```
/mnt/e/worktree/issue-1/
β”β”€β”€ .env                                    # ν™κ²½λ³€μ μ„¤μ •
β”β”€β”€ Makefile                               # make up-p1, make down λ…λ Ή
β”β”€β”€ docker/compose.p1.yml                 # Docker Compose μ„¤μ •
β”β”€β”€ services/api-gateway/config.p1.yaml   # LiteLLM μ„¤μ •
β”β”€β”€ models/
β”‚   β”β”€β”€ qwen2.5-14b-instruct-q4_k_m.gguf     # μΌλ° λ¨λΈ (8.4GB)
β”‚   β””β”€β”€ qwen2.5-coder-14b-instruct-q4_k_m.gguf # μ½”λ” λ¨λΈ (8.4GB)
β””β”€β”€ docs/progress/v1/ri_1.md              # μ›λ³Έ κ³„ν λ¬Έμ„
```

---

## π― Phase 1 μµμΆ… λ©ν‘ μƒνƒ

**μ™„λ£ κΈ°μ¤€:**
- [x] `make up-p1` λ…λ ΉμΌλ΅ μ„λΉ„μ¤ μ •μƒ μ‹¤ν–‰
- [x] `curl http://localhost:8001/v1/models` μ •μƒ μ‘λ‹µ β…
- [x] `curl http://localhost:8001/v1/chat/completions` μ •μƒ μ‘λ‹µ β…
- [ ] `curl http://localhost:8000/v1/models` μ •μƒ μ‘λ‹µ (API Gateway)
- [ ] `curl http://localhost:8000/v1/chat/completions` μ •μƒ μ‘λ‹µ (API Gateway)
- [ ] VS Code/Cursorμ—μ„ `http://localhost:8000/v1` μ—°κ²° μ„±κ³µ

**ν•µμ‹¬ μ„±κ³Ό:**
- λ΅μ»¬ GGUF λ¨λΈ β†’ OpenAI νΈν™ API μ„λΉ™ β… (λ¶€λ¶„ μ„±κ³µ)
- RTX 4050 + WSL2 ν™κ²½μ—μ„ GPU ν™μ© β…
- ν•κµ­μ–΄ μ§λ¬Έ/μ‘λ‹µ μ •μƒ λ™μ‘ β…

---

## π€ μ¬μ‹μ‘ λ…λ Ήμ–΄

```bash
# ν„μ¬ μ„μΉ ν™•μΈ
cd /mnt/e/worktree/issue-1

# μ„λΉ„μ¤ μƒνƒ ν™•μΈ
docker ps
make down

# μ„¤μ • μμ • ν›„ μ¬μ‹μ‘
make up-p1

# ν…μ¤νΈ
curl -s http://localhost:8001/v1/models  # μ¶”λ΅  μ„λ²„ (λ™μ‘ν•¨)
curl -s http://localhost:8000/v1/models  # API Gateway (μμ • ν•„μ”)
```

---

**β° λ§μ§€λ§‰ μ—…λ°μ΄νΈ:** 2025-09-22 21:13
**β­οΈ λ‹¤μ μ‘μ—…:** LiteLLM API Gateway μ„¤μ • μμ • λ° μ™„μ „ν• OpenAI νΈν™ API κµ¬ν„